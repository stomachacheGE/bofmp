{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "# % matplotlib inline\n",
    "#plt.rcParams['animation.html'] = 'jshtml'\n",
    "from IPython.display import HTML\n",
    "\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "from functools import reduce\n",
    "sys.path.append(\"/home/ful7rng/projects/transition/propagation\")\n",
    "from utils import pickle_load, get_npy, get_file\n",
    "from utils.occ_map_utils import load_map, show_map, plot_occ_map, plot_trajectories, free_space\n",
    "from utils.plot_utils import plot_4d_tensor\n",
    "from utils.scene_utils import display_scenes_trajs, animate_scenes, get_scenes\n",
    "from propagation.bofum import conditionalBOFUM, naiveBOFUM, BOFUMRealdata\n",
    "from propagation.animation import TrackingAnimRealdata, Plot\n",
    "from data_loader import get_map_crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diagonal = True\n",
    "if diagonal:\n",
    "    model_name = '04_DIAGONAL_TRUE_CONDITIONAL_TRUE'\n",
    "else:\n",
    "    model_name = '20_ALL_MAPS_W_MASK'\n",
    "    # model_name = '01_JOINT_PROB_ALL_MAPS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show nn_output and kernel at map location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27119, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "from propagation.bofum import conditionalBOFUM, naiveBOFUM\n",
    "from data_loader import get_map_crop\n",
    "\n",
    "config_path = '/local/home/ful7rng/projects/transition/config_diagonal_True_conditional_True.py'\n",
    "maps, outputs = get_map_crop(config_path, num=1, dataset='train', probs=True)\n",
    "map_ = maps[0]\n",
    "output = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 8, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 19]\n",
      "[[ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.08474576  0.08474576  0.08474576  0.08474576  0.08474576  0.49152542\n",
      "   0.          0.08474576]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          1.\n",
      "   0.        ]]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.random.randint(0, 32), np.random.randint(0, 32)\n",
    "print([x, y])\n",
    "print(output[x, y])\n",
    "print(np.sum(output[x, y], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(omega=0.05,\n",
    "              noise_var=0.5,\n",
    "              extent=7,\n",
    "              verbose=False)\n",
    "\n",
    "bofum = conditionalBOFUM(map_, model_name,\n",
    "                                   name = 'BOFUM with n. o. as acceleration',\n",
    "                                   simulated_data=True,\n",
    "                                   nn_probs=output,\n",
    "                                   force_predict=True,\n",
    "                                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories: 1/3\n"
     ]
    }
   ],
   "source": [
    "distances, trajs = bofum.initialize(num_targets=3, num_steps=20, diagonal=diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bofum.show_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def onclick(event, bofum, fig, fig_1, fig_2, plot):\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    coords = np.floor(np.array([ix, iy]) / bofum.map_res).astype(int)\n",
    "    print(coords)\n",
    "    \n",
    "    clicked = np.zeros_like(bofum.map)\n",
    "    x, y = coords[0], coords[1]\n",
    "    clicked[x, y] = 1\n",
    "    plot.set_axes_data(\"occupancy_axes\", clicked)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    fig_1.clear()\n",
    "    fig_2.clear()\n",
    "    probs = bofum.nn_probs\n",
    "    prob = probs[x, y]\n",
    "    print(np.rot90(np.sum(prob, axis=(2, 3))))\n",
    "    print(np.sum(prob))\n",
    "    plot_4d_tensor(prob, fig=fig_1)\n",
    "    plot_4d_tensor(bofum.kernels[x, y], fig=fig_2)\n",
    "    print(\"kernel sum is : \"+ str(np.sum(bofum.kernels[x, y])))\n",
    "    #plot_4d_tensor(transition_counts[x, y], fig=fig_2)\n",
    "    fig_1.canvas.draw()\n",
    "    fig_2.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 19]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[23 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 7 18]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 7 16]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 1 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 2 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 2 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 1 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 2 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 2 13]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 2 12]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 8 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n",
      "[ 9 14]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "8.0\n",
      "kernel sum is : 49.0\n"
     ]
    }
   ],
   "source": [
    "from propagation.animation import Plot\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "fig_1 = plt.figure(figsize=(6, 5))\n",
    "fig_2 = plt.figure(figsize=(6, 5))\n",
    "\n",
    "map_axes = fig.add_subplot(111)\n",
    "plot = Plot(map_axes, bofum.map, bofum.map_res)\n",
    "fig.canvas.mpl_connect('button_press_event', lambda event: onclick(event, bofum, fig, fig_1, fig_2, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conditional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2b15e412e3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                    \u001b[0mnn_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                    \u001b[0mforce_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                    \u001b[0mconditional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconditional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                                    \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                    **kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conditional' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 17]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[10 17]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[12 15]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[12 16]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[8 6]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[8 5]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[8 4]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[18  8]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[15  5]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[15  4]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[15  5]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n",
      "[15  4]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "kernel sum is : 49.0\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(omega=0.05,\n",
    "              noise_var=0.5,\n",
    "              extent=7,\n",
    "              verbose=False)\n",
    "\n",
    "bofum_1 = conditionalBOFUM(map_, model_name,\n",
    "                                   name = 'BOFUM with n. o. as acceleration',\n",
    "                                   simulated_data=True,\n",
    "                                   with_reachability=True,\n",
    "                                   acceleration_interpretation=True,\n",
    "                                   nn_probs=output,\n",
    "                                   force_predict=True,\n",
    "                                   conditional=conditional,\n",
    "                                   config=config,\n",
    "                                   **kwargs)\n",
    "\n",
    "distances, trajs = bofum_1.initialize(num_targets=1, num_steps=20, diagonal=False)\n",
    "\n",
    "from propagation.animation import Plot\n",
    "fig_3 = plt.figure(figsize=(5, 5))\n",
    "fig_4 = plt.figure(figsize=(6, 5))\n",
    "fig_5 = plt.figure(figsize=(6, 5))\n",
    "\n",
    "map_axes_1 = fig_3.add_subplot(111)\n",
    "plot_1 = Plot(map_axes_1, bofum_1.map, bofum_1.map_res)\n",
    "fig_3.canvas.mpl_connect('button_press_event', lambda event: onclick(event, bofum_1, fig_3, fig_4, fig_5, plot_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "Warning : all the layers are not displayed \n",
      "\n",
      "    Layer           Output shape         W shape             \n",
      "1   Input           (None, 1, None, None)                     \n",
      "2   Conv2D          (None, 8, None, None) (8, 1, 1, 1)        \n",
      "3   Conv2D          (None, 12, None, None) (12, 8, 3, 3)       \n",
      "4   Concat          (None, 20, None, None)                     \n",
      "5   Conv2D          (None, 12, None, None) (12, 20, 3, 3)      \n",
      "6   Concat          (None, 32, None, None)                     \n",
      "7   Conv2D          (None, 12, None, None) (12, 32, 3, 3)      \n",
      "8   Concat          (None, 44, None, None)                     \n",
      "9   Conv2D          (None, 12, None, None) (12, 44, 3, 3)      \n",
      "10  Concat          (None, 56, None, None)                     \n",
      "11  Conv2D          (None, 12, None, None) (12, 56, 3, 3)      \n",
      "12  Concat          (None, 68, None, None)                     \n",
      "13  Conv2D          (None, 68, None, None) (68, 68, 1, 1)      \n",
      "14  Pool2D          (None, 68, None, None)                     \n",
      "\n",
      "15  Conv2D          (None, 12, None, None) (12, 68, 3, 3)      \n",
      "16  Concat          (None, 80, None, None)                     \n",
      "17  Conv2D          (None, 12, None, None) (12, 80, 3, 3)      \n",
      "18  Concat          (None, 92, None, None)                     \n",
      "19  Conv2D          (None, 12, None, None) (12, 92, 3, 3)      \n",
      "20  Concat          (None, 104, None, None)                     \n",
      "21  Conv2D          (None, 12, None, None) (12, 104, 3, 3)     \n",
      "22  Concat          (None, 116, None, None)                     \n",
      "23  Conv2D          (None, 12, None, None) (12, 116, 3, 3)     \n",
      "24  Concat          (None, 128, None, None)                     \n",
      "25  Conv2D          (None, 128, None, None) (128, 128, 1, 1)    \n",
      "26  Pool2D          (None, 128, None, None)                     \n",
      "\n",
      "27  Conv2D          (None, 12, None, None) (12, 128, 3, 3)     \n",
      "28  Concat          (None, 140, None, None)                     \n",
      "29  Conv2D          (None, 12, None, None) (12, 140, 3, 3)     \n",
      "30  Concat          (None, 152, None, None)                     \n",
      "31  Conv2D          (None, 12, None, None) (12, 152, 3, 3)     \n",
      "32  Concat          (None, 164, None, None)                     \n",
      "33  Conv2D          (None, 12, None, None) (12, 164, 3, 3)     \n",
      "34  Concat          (None, 176, None, None)                     \n",
      "35  Conv2D          (None, 12, None, None) (12, 176, 3, 3)     \n",
      "36  Concat          (None, 60, None, None)                     \n",
      "37  TransposedConv2D (None, 60, None, None) (60, 60, 3, 3)      \n",
      "\n",
      "38  Concat          (None, 188, None, None)                     \n",
      "39  Conv2D          (None, 12, None, None) (12, 188, 3, 3)     \n",
      "40  Concat          (None, 200, None, None)                     \n",
      "41  Conv2D          (None, 12, None, None) (12, 200, 3, 3)     \n",
      "42  Concat          (None, 212, None, None)                     \n",
      "43  Conv2D          (None, 12, None, None) (12, 212, 3, 3)     \n",
      "44  Concat          (None, 224, None, None)                     \n",
      "45  Conv2D          (None, 12, None, None) (12, 224, 3, 3)     \n",
      "46  Concat          (None, 236, None, None)                     \n",
      "47  Conv2D          (None, 12, None, None) (12, 236, 3, 3)     \n",
      "48  Concat          (None, 60, None, None)                     \n",
      "49  TransposedConv2D (None, 60, None, None) (60, 60, 3, 3)      \n",
      "\n",
      "50  Concat          (None, 128, None, None)                     \n",
      "51  Conv2D          (None, 12, None, None) (12, 128, 3, 3)     \n",
      "52  Concat          (None, 140, None, None)                     \n",
      "53  Conv2D          (None, 12, None, None) (12, 140, 3, 3)     \n",
      "54  Concat          (None, 152, None, None)                     \n",
      "55  Conv2D          (None, 12, None, None) (12, 152, 3, 3)     \n",
      "56  Concat          (None, 164, None, None)                     \n",
      "57  Conv2D          (None, 12, None, None) (12, 164, 3, 3)     \n",
      "58  Concat          (None, 176, None, None)                     \n",
      "59  Conv2D          (None, 12, None, None) (12, 176, 3, 3)     \n",
      "60  Concat          (None, 188, None, None)                     \n",
      "61  Conv2D          (None, 6, None, None) (6, 188, 1, 1)      \n",
      "\n",
      "Number of Convolutional layers : 31\n",
      "Number of parameters : 446758\n",
      "---------------------------------------------------------------------------\n",
      "Compiling function\n",
      "Compilation took 13.048 seconds\n",
      "sampling trajectories: 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 26]\n",
      "[[ 0.          0.16129032  0.        ]\n",
      " [ 0.37903226  0.          0.2983871 ]\n",
      " [ 0.          0.16129032  0.        ]]\n",
      "1.0\n",
      "kernel sum is : 49.0\n",
      "[27 26]\n",
      "[[ 0.          0.31111111  0.        ]\n",
      " [ 0.20555556  0.          0.16111111]\n",
      " [ 0.          0.32222222  0.        ]]\n",
      "1.0\n",
      "kernel sum is : 49.0\n",
      "[27 26]\n",
      "[[ 0.          0.4575373   0.        ]\n",
      " [ 0.0235649   0.          0.03274885]\n",
      " [ 0.          0.48614893  0.        ]]\n",
      "0.999999977183\n",
      "kernel sum is : 49.0\n",
      "[28 26]\n",
      "[[ 0.          0.39228304  0.        ]\n",
      " [ 0.09305708  0.          0.08540007]\n",
      " [ 0.          0.4292598   0.        ]]\n",
      "0.999999990687\n",
      "kernel sum is : 49.0\n",
      "[29 26]\n",
      "[[ 0.          0.33182057  0.        ]\n",
      " [ 0.1566642   0.          0.14354769]\n",
      " [ 0.          0.36796752  0.        ]]\n",
      "0.999999977648\n",
      "kernel sum is : 49.0\n",
      "[29 26]\n",
      "[[ 0.        0.309375  0.      ]\n",
      " [ 0.14375   0.        0.175   ]\n",
      " [ 0.        0.371875  0.      ]]\n",
      "1.0\n",
      "kernel sum is : 49.0\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(omega=0.05,\n",
    "              noise_var=0.5,\n",
    "              extent=7,\n",
    "              verbose=False)\n",
    "\n",
    "bofum_2 = conditionalBOFUM(map_, model_name,\n",
    "                                   name = 'BOFUM with n. o. as acceleration',\n",
    "                                   simulated_data=True,\n",
    "                                   with_reachability=True,\n",
    "                                   acceleration_interpretation=True,\n",
    "                                   nn_probs=None,\n",
    "                                   force_predict=True,\n",
    "                                   conditional=conditional,\n",
    "                                   config=config,\n",
    "                                   **kwargs)\n",
    "\n",
    "distances, trajs = bofum_2.initialize(num_targets=1, num_steps=20, diagonal=False)\n",
    "\n",
    "from propagation.animation import Plot\n",
    "fig_6 = plt.figure(figsize=(5, 5))\n",
    "fig_7 = plt.figure(figsize=(6, 5))\n",
    "fig_8 = plt.figure(figsize=(6, 5))\n",
    "\n",
    "map_axes_2 = fig_6.add_subplot(111)\n",
    "plot_2 = Plot(map_axes_2, bofum_2.map, bofum_2.map_res)\n",
    "fig_6.canvas.mpl_connect('button_press_event', lambda event: onclick(event, bofum_2, fig_6, fig_7, fig_8, plot_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate rescale trajectory and recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj = trajs[0]\n",
    "# rescale traj\n",
    "res = 0.2\n",
    "traj_scaled = np.array(traj + np.array([0.5] * 2)) * res\n",
    "# recover traj\n",
    "traj_recoverd = np.round((traj_scaled / res) - 0.5).astype(int)\n",
    "\n",
    "assert (traj_recoverd == traj).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate transition probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 1/460\n",
      "sampling trajectories for possible start locations: 2/460\n",
      "sampling trajectories for possible start locations: 3/460\n",
      "sampling trajectories for possible start locations: 4/460\n",
      "sampling trajectories for possible start locations: 5/460\n",
      "sampling trajectories for possible start locations: 6/460\n",
      "sampling trajectories for possible start locations: 7/460\n",
      "sampling trajectories for possible start locations: 8/460\n",
      "sampling trajectories for possible start locations: 9/460\n",
      "sampling trajectories for possible start locations: 10/460\n",
      "sampling trajectories for possible start locations: 11/460\n",
      "sampling trajectories for possible start locations: 12/460\n",
      "sampling trajectories for possible start locations: 13/460\n",
      "sampling trajectories for possible start locations: 14/460\n",
      "sampling trajectories for possible start locations: 15/460\n",
      "sampling trajectories for possible start locations: 16/460\n",
      "sampling trajectories for possible start locations: 17/460\n",
      "sampling trajectories for possible start locations: 18/460\n",
      "sampling trajectories for possible start locations: 19/460\n",
      "sampling trajectories for possible start locations: 20/460\n",
      "sampling trajectories for possible start locations: 21/460\n",
      "sampling trajectories for possible start locations: 22/460\n",
      "sampling trajectories for possible start locations: 23/460\n",
      "sampling trajectories for possible start locations: 24/460\n",
      "sampling trajectories for possible start locations: 25/460\n",
      "sampling trajectories for possible start locations: 26/460\n",
      "sampling trajectories for possible start locations: 27/460\n",
      "sampling trajectories for possible start locations: 28/460\n",
      "sampling trajectories for possible start locations: 29/460\n",
      "sampling trajectories for possible start locations: 30/460\n",
      "sampling trajectories for possible start locations: 31/460\n",
      "sampling trajectories for possible start locations: 32/460\n",
      "sampling trajectories for possible start locations: 33/460\n",
      "sampling trajectories for possible start locations: 34/460\n",
      "sampling trajectories for possible start locations: 35/460\n",
      "sampling trajectories for possible start locations: 36/460\n",
      "sampling trajectories for possible start locations: 37/460\n",
      "sampling trajectories for possible start locations: 38/460\n",
      "sampling trajectories for possible start locations: 39/460\n",
      "sampling trajectories for possible start locations: 40/460\n",
      "sampling trajectories for possible start locations: 41/460\n",
      "sampling trajectories for possible start locations: 42/460\n",
      "sampling trajectories for possible start locations: 43/460\n",
      "sampling trajectories for possible start locations: 44/460\n",
      "sampling trajectories for possible start locations: 45/460\n",
      "sampling trajectories for possible start locations: 46/460\n",
      "sampling trajectories for possible start locations: 47/460\n",
      "sampling trajectories for possible start locations: 48/460\n",
      "sampling trajectories for possible start locations: 49/460\n",
      "sampling trajectories for possible start locations: 50/460\n",
      "sampling trajectories for possible start locations: 51/460\n",
      "sampling trajectories for possible start locations: 52/460\n",
      "sampling trajectories for possible start locations: 53/460\n",
      "sampling trajectories for possible start locations: 54/460\n",
      "sampling trajectories for possible start locations: 55/460\n",
      "sampling trajectories for possible start locations: 56/460\n",
      "sampling trajectories for possible start locations: 57/460\n",
      "sampling trajectories for possible start locations: 58/460\n",
      "sampling trajectories for possible start locations: 59/460\n",
      "sampling trajectories for possible start locations: 60/460\n",
      "sampling trajectories for possible start locations: 61/460\n",
      "sampling trajectories for possible start locations: 62/460\n",
      "sampling trajectories for possible start locations: 63/460\n",
      "sampling trajectories for possible start locations: 64/460\n",
      "sampling trajectories for possible start locations: 65/460\n",
      "sampling trajectories for possible start locations: 66/460\n",
      "sampling trajectories for possible start locations: 67/460\n",
      "sampling trajectories for possible start locations: 68/460\n",
      "sampling trajectories for possible start locations: 69/460\n",
      "sampling trajectories for possible start locations: 70/460\n",
      "sampling trajectories for possible start locations: 71/460\n",
      "sampling trajectories for possible start locations: 72/460\n",
      "sampling trajectories for possible start locations: 73/460\n",
      "sampling trajectories for possible start locations: 74/460\n",
      "sampling trajectories for possible start locations: 75/460\n",
      "sampling trajectories for possible start locations: 76/460\n",
      "sampling trajectories for possible start locations: 77/460\n",
      "sampling trajectories for possible start locations: 78/460\n",
      "sampling trajectories for possible start locations: 79/460\n",
      "sampling trajectories for possible start locations: 80/460\n",
      "sampling trajectories for possible start locations: 81/460\n",
      "sampling trajectories for possible start locations: 82/460\n",
      "sampling trajectories for possible start locations: 83/460\n",
      "sampling trajectories for possible start locations: 84/460\n",
      "sampling trajectories for possible start locations: 85/460\n",
      "sampling trajectories for possible start locations: 86/460\n",
      "sampling trajectories for possible start locations: 87/460\n",
      "sampling trajectories for possible start locations: 88/460\n",
      "sampling trajectories for possible start locations: 89/460\n",
      "sampling trajectories for possible start locations: 90/460\n",
      "sampling trajectories for possible start locations: 91/460\n",
      "sampling trajectories for possible start locations: 92/460\n",
      "sampling trajectories for possible start locations: 93/460\n",
      "sampling trajectories for possible start locations: 94/460\n",
      "sampling trajectories for possible start locations: 95/460\n",
      "sampling trajectories for possible start locations: 96/460\n",
      "sampling trajectories for possible start locations: 97/460\n",
      "sampling trajectories for possible start locations: 98/460\n",
      "sampling trajectories for possible start locations: 99/460\n",
      "sampling trajectories for possible start locations: 100/460\n",
      "sampling trajectories for possible start locations: 101/460\n",
      "sampling trajectories for possible start locations: 102/460\n",
      "sampling trajectories for possible start locations: 103/460\n",
      "sampling trajectories for possible start locations: 104/460\n",
      "sampling trajectories for possible start locations: 105/460\n",
      "sampling trajectories for possible start locations: 106/460\n",
      "sampling trajectories for possible start locations: 107/460\n",
      "sampling trajectories for possible start locations: 108/460\n",
      "sampling trajectories for possible start locations: 109/460\n",
      "sampling trajectories for possible start locations: 110/460\n",
      "sampling trajectories for possible start locations: 111/460\n",
      "sampling trajectories for possible start locations: 112/460\n",
      "sampling trajectories for possible start locations: 113/460\n",
      "sampling trajectories for possible start locations: 114/460\n",
      "sampling trajectories for possible start locations: 115/460\n",
      "sampling trajectories for possible start locations: 116/460\n",
      "sampling trajectories for possible start locations: 117/460\n",
      "sampling trajectories for possible start locations: 118/460\n",
      "sampling trajectories for possible start locations: 119/460\n",
      "sampling trajectories for possible start locations: 120/460\n",
      "sampling trajectories for possible start locations: 121/460\n",
      "sampling trajectories for possible start locations: 122/460\n",
      "sampling trajectories for possible start locations: 123/460\n",
      "sampling trajectories for possible start locations: 124/460\n",
      "sampling trajectories for possible start locations: 125/460\n",
      "sampling trajectories for possible start locations: 126/460\n",
      "sampling trajectories for possible start locations: 127/460\n",
      "sampling trajectories for possible start locations: 128/460\n",
      "sampling trajectories for possible start locations: 129/460\n",
      "sampling trajectories for possible start locations: 130/460\n",
      "sampling trajectories for possible start locations: 131/460\n",
      "sampling trajectories for possible start locations: 132/460\n",
      "sampling trajectories for possible start locations: 133/460\n",
      "sampling trajectories for possible start locations: 134/460\n",
      "sampling trajectories for possible start locations: 135/460\n",
      "sampling trajectories for possible start locations: 136/460\n",
      "sampling trajectories for possible start locations: 137/460\n",
      "sampling trajectories for possible start locations: 138/460\n",
      "sampling trajectories for possible start locations: 139/460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 140/460\n",
      "sampling trajectories for possible start locations: 141/460\n",
      "sampling trajectories for possible start locations: 142/460\n",
      "sampling trajectories for possible start locations: 143/460\n",
      "sampling trajectories for possible start locations: 144/460\n",
      "sampling trajectories for possible start locations: 145/460\n",
      "sampling trajectories for possible start locations: 146/460\n",
      "sampling trajectories for possible start locations: 147/460\n",
      "sampling trajectories for possible start locations: 148/460\n",
      "sampling trajectories for possible start locations: 149/460\n",
      "sampling trajectories for possible start locations: 150/460\n",
      "sampling trajectories for possible start locations: 151/460\n",
      "sampling trajectories for possible start locations: 152/460\n",
      "sampling trajectories for possible start locations: 153/460\n",
      "sampling trajectories for possible start locations: 154/460\n",
      "sampling trajectories for possible start locations: 155/460\n",
      "sampling trajectories for possible start locations: 156/460\n",
      "sampling trajectories for possible start locations: 157/460\n",
      "sampling trajectories for possible start locations: 158/460\n",
      "sampling trajectories for possible start locations: 159/460\n",
      "sampling trajectories for possible start locations: 160/460\n",
      "sampling trajectories for possible start locations: 161/460\n",
      "sampling trajectories for possible start locations: 162/460\n",
      "sampling trajectories for possible start locations: 163/460\n",
      "sampling trajectories for possible start locations: 164/460\n",
      "sampling trajectories for possible start locations: 165/460\n",
      "sampling trajectories for possible start locations: 166/460\n",
      "sampling trajectories for possible start locations: 167/460\n",
      "sampling trajectories for possible start locations: 168/460\n",
      "sampling trajectories for possible start locations: 169/460\n",
      "sampling trajectories for possible start locations: 170/460\n",
      "sampling trajectories for possible start locations: 171/460\n",
      "sampling trajectories for possible start locations: 172/460\n",
      "sampling trajectories for possible start locations: 173/460\n",
      "sampling trajectories for possible start locations: 174/460\n",
      "sampling trajectories for possible start locations: 175/460\n",
      "sampling trajectories for possible start locations: 176/460\n",
      "sampling trajectories for possible start locations: 177/460\n",
      "sampling trajectories for possible start locations: 178/460\n",
      "sampling trajectories for possible start locations: 179/460\n",
      "sampling trajectories for possible start locations: 180/460\n",
      "sampling trajectories for possible start locations: 181/460\n",
      "sampling trajectories for possible start locations: 182/460\n",
      "sampling trajectories for possible start locations: 183/460\n",
      "sampling trajectories for possible start locations: 184/460\n",
      "sampling trajectories for possible start locations: 185/460\n",
      "sampling trajectories for possible start locations: 186/460\n",
      "sampling trajectories for possible start locations: 187/460\n",
      "sampling trajectories for possible start locations: 188/460\n",
      "sampling trajectories for possible start locations: 189/460\n",
      "sampling trajectories for possible start locations: 190/460\n",
      "sampling trajectories for possible start locations: 191/460\n",
      "sampling trajectories for possible start locations: 192/460\n",
      "sampling trajectories for possible start locations: 193/460\n",
      "sampling trajectories for possible start locations: 194/460\n",
      "sampling trajectories for possible start locations: 195/460\n",
      "sampling trajectories for possible start locations: 196/460\n",
      "sampling trajectories for possible start locations: 197/460\n",
      "sampling trajectories for possible start locations: 198/460\n",
      "sampling trajectories for possible start locations: 199/460\n",
      "sampling trajectories for possible start locations: 200/460\n",
      "sampling trajectories for possible start locations: 201/460\n",
      "sampling trajectories for possible start locations: 202/460\n",
      "sampling trajectories for possible start locations: 203/460\n",
      "sampling trajectories for possible start locations: 204/460\n",
      "sampling trajectories for possible start locations: 205/460\n",
      "sampling trajectories for possible start locations: 206/460\n",
      "sampling trajectories for possible start locations: 207/460\n",
      "sampling trajectories for possible start locations: 208/460\n",
      "sampling trajectories for possible start locations: 209/460\n",
      "sampling trajectories for possible start locations: 210/460\n",
      "sampling trajectories for possible start locations: 211/460\n",
      "sampling trajectories for possible start locations: 212/460\n",
      "sampling trajectories for possible start locations: 213/460\n",
      "sampling trajectories for possible start locations: 214/460\n",
      "sampling trajectories for possible start locations: 215/460\n",
      "sampling trajectories for possible start locations: 216/460\n",
      "sampling trajectories for possible start locations: 217/460\n",
      "sampling trajectories for possible start locations: 218/460\n",
      "sampling trajectories for possible start locations: 219/460\n",
      "sampling trajectories for possible start locations: 220/460\n",
      "sampling trajectories for possible start locations: 221/460\n",
      "sampling trajectories for possible start locations: 222/460\n",
      "sampling trajectories for possible start locations: 223/460\n",
      "sampling trajectories for possible start locations: 224/460\n",
      "sampling trajectories for possible start locations: 225/460\n",
      "sampling trajectories for possible start locations: 226/460\n",
      "sampling trajectories for possible start locations: 227/460\n",
      "sampling trajectories for possible start locations: 228/460\n",
      "sampling trajectories for possible start locations: 229/460\n",
      "sampling trajectories for possible start locations: 230/460\n",
      "sampling trajectories for possible start locations: 231/460\n",
      "sampling trajectories for possible start locations: 232/460\n",
      "sampling trajectories for possible start locations: 233/460\n",
      "sampling trajectories for possible start locations: 234/460\n",
      "sampling trajectories for possible start locations: 235/460\n",
      "sampling trajectories for possible start locations: 236/460\n",
      "sampling trajectories for possible start locations: 237/460\n",
      "sampling trajectories for possible start locations: 238/460\n",
      "sampling trajectories for possible start locations: 239/460\n",
      "sampling trajectories for possible start locations: 240/460\n",
      "sampling trajectories for possible start locations: 241/460\n",
      "sampling trajectories for possible start locations: 242/460\n",
      "sampling trajectories for possible start locations: 243/460\n",
      "sampling trajectories for possible start locations: 244/460\n",
      "sampling trajectories for possible start locations: 245/460\n",
      "sampling trajectories for possible start locations: 246/460\n",
      "sampling trajectories for possible start locations: 247/460\n",
      "sampling trajectories for possible start locations: 248/460\n",
      "sampling trajectories for possible start locations: 249/460\n",
      "sampling trajectories for possible start locations: 250/460\n",
      "sampling trajectories for possible start locations: 251/460\n",
      "sampling trajectories for possible start locations: 252/460\n",
      "sampling trajectories for possible start locations: 253/460\n",
      "sampling trajectories for possible start locations: 254/460\n",
      "sampling trajectories for possible start locations: 255/460\n",
      "sampling trajectories for possible start locations: 256/460\n",
      "sampling trajectories for possible start locations: 257/460\n",
      "sampling trajectories for possible start locations: 258/460\n",
      "sampling trajectories for possible start locations: 259/460\n",
      "sampling trajectories for possible start locations: 260/460\n",
      "sampling trajectories for possible start locations: 261/460\n",
      "sampling trajectories for possible start locations: 262/460\n",
      "sampling trajectories for possible start locations: 263/460\n",
      "sampling trajectories for possible start locations: 264/460\n",
      "sampling trajectories for possible start locations: 265/460\n",
      "sampling trajectories for possible start locations: 266/460\n",
      "sampling trajectories for possible start locations: 267/460\n",
      "sampling trajectories for possible start locations: 268/460\n",
      "sampling trajectories for possible start locations: 269/460\n",
      "sampling trajectories for possible start locations: 270/460\n",
      "sampling trajectories for possible start locations: 271/460\n",
      "sampling trajectories for possible start locations: 272/460\n",
      "sampling trajectories for possible start locations: 273/460\n",
      "sampling trajectories for possible start locations: 274/460\n",
      "sampling trajectories for possible start locations: 275/460\n",
      "sampling trajectories for possible start locations: 276/460\n",
      "sampling trajectories for possible start locations: 277/460\n",
      "sampling trajectories for possible start locations: 278/460\n",
      "sampling trajectories for possible start locations: 279/460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 280/460\n",
      "sampling trajectories for possible start locations: 281/460\n",
      "sampling trajectories for possible start locations: 282/460\n",
      "sampling trajectories for possible start locations: 283/460\n",
      "sampling trajectories for possible start locations: 284/460\n",
      "sampling trajectories for possible start locations: 285/460\n",
      "sampling trajectories for possible start locations: 286/460\n",
      "sampling trajectories for possible start locations: 287/460\n",
      "sampling trajectories for possible start locations: 288/460\n",
      "sampling trajectories for possible start locations: 289/460\n",
      "sampling trajectories for possible start locations: 290/460\n",
      "sampling trajectories for possible start locations: 291/460\n",
      "sampling trajectories for possible start locations: 292/460\n",
      "sampling trajectories for possible start locations: 293/460\n",
      "sampling trajectories for possible start locations: 294/460\n",
      "sampling trajectories for possible start locations: 295/460\n",
      "sampling trajectories for possible start locations: 296/460\n",
      "sampling trajectories for possible start locations: 297/460\n",
      "sampling trajectories for possible start locations: 298/460\n",
      "sampling trajectories for possible start locations: 299/460\n",
      "sampling trajectories for possible start locations: 300/460\n",
      "sampling trajectories for possible start locations: 301/460\n",
      "sampling trajectories for possible start locations: 302/460\n",
      "sampling trajectories for possible start locations: 303/460\n",
      "sampling trajectories for possible start locations: 304/460\n",
      "sampling trajectories for possible start locations: 305/460\n",
      "sampling trajectories for possible start locations: 306/460\n",
      "sampling trajectories for possible start locations: 307/460\n",
      "sampling trajectories for possible start locations: 308/460\n",
      "sampling trajectories for possible start locations: 309/460\n",
      "sampling trajectories for possible start locations: 310/460\n",
      "sampling trajectories for possible start locations: 311/460\n",
      "sampling trajectories for possible start locations: 312/460\n",
      "sampling trajectories for possible start locations: 313/460\n",
      "sampling trajectories for possible start locations: 314/460\n",
      "sampling trajectories for possible start locations: 315/460\n",
      "sampling trajectories for possible start locations: 316/460\n",
      "sampling trajectories for possible start locations: 317/460\n",
      "sampling trajectories for possible start locations: 318/460\n",
      "sampling trajectories for possible start locations: 319/460\n",
      "sampling trajectories for possible start locations: 320/460\n",
      "sampling trajectories for possible start locations: 321/460\n",
      "sampling trajectories for possible start locations: 322/460\n",
      "sampling trajectories for possible start locations: 323/460\n",
      "sampling trajectories for possible start locations: 324/460\n",
      "sampling trajectories for possible start locations: 325/460\n",
      "sampling trajectories for possible start locations: 326/460\n",
      "sampling trajectories for possible start locations: 327/460\n",
      "sampling trajectories for possible start locations: 328/460\n",
      "sampling trajectories for possible start locations: 329/460\n",
      "sampling trajectories for possible start locations: 330/460\n",
      "sampling trajectories for possible start locations: 331/460\n",
      "sampling trajectories for possible start locations: 332/460\n",
      "sampling trajectories for possible start locations: 333/460\n",
      "sampling trajectories for possible start locations: 334/460\n",
      "sampling trajectories for possible start locations: 335/460\n",
      "sampling trajectories for possible start locations: 336/460\n",
      "sampling trajectories for possible start locations: 337/460\n",
      "sampling trajectories for possible start locations: 338/460\n",
      "sampling trajectories for possible start locations: 339/460\n",
      "sampling trajectories for possible start locations: 340/460\n",
      "sampling trajectories for possible start locations: 341/460\n",
      "sampling trajectories for possible start locations: 342/460\n",
      "sampling trajectories for possible start locations: 343/460\n",
      "sampling trajectories for possible start locations: 344/460\n",
      "sampling trajectories for possible start locations: 345/460\n",
      "sampling trajectories for possible start locations: 346/460\n",
      "sampling trajectories for possible start locations: 347/460\n",
      "sampling trajectories for possible start locations: 348/460\n",
      "sampling trajectories for possible start locations: 349/460\n",
      "sampling trajectories for possible start locations: 350/460\n",
      "sampling trajectories for possible start locations: 351/460\n",
      "sampling trajectories for possible start locations: 352/460\n",
      "sampling trajectories for possible start locations: 353/460\n",
      "sampling trajectories for possible start locations: 354/460\n",
      "sampling trajectories for possible start locations: 355/460\n",
      "sampling trajectories for possible start locations: 356/460\n",
      "sampling trajectories for possible start locations: 357/460\n",
      "sampling trajectories for possible start locations: 358/460\n",
      "sampling trajectories for possible start locations: 359/460\n",
      "sampling trajectories for possible start locations: 360/460\n",
      "sampling trajectories for possible start locations: 361/460\n",
      "sampling trajectories for possible start locations: 362/460\n",
      "sampling trajectories for possible start locations: 363/460\n",
      "sampling trajectories for possible start locations: 364/460\n",
      "sampling trajectories for possible start locations: 365/460\n",
      "sampling trajectories for possible start locations: 366/460\n",
      "sampling trajectories for possible start locations: 367/460\n",
      "sampling trajectories for possible start locations: 368/460\n",
      "sampling trajectories for possible start locations: 369/460\n",
      "sampling trajectories for possible start locations: 370/460\n",
      "sampling trajectories for possible start locations: 371/460\n",
      "sampling trajectories for possible start locations: 372/460\n",
      "sampling trajectories for possible start locations: 373/460\n",
      "sampling trajectories for possible start locations: 374/460\n",
      "sampling trajectories for possible start locations: 375/460\n",
      "sampling trajectories for possible start locations: 376/460\n",
      "sampling trajectories for possible start locations: 377/460\n",
      "sampling trajectories for possible start locations: 378/460\n",
      "sampling trajectories for possible start locations: 379/460\n",
      "sampling trajectories for possible start locations: 380/460\n",
      "sampling trajectories for possible start locations: 381/460\n",
      "sampling trajectories for possible start locations: 382/460\n",
      "sampling trajectories for possible start locations: 383/460\n",
      "sampling trajectories for possible start locations: 384/460\n",
      "sampling trajectories for possible start locations: 385/460\n",
      "sampling trajectories for possible start locations: 386/460\n",
      "sampling trajectories for possible start locations: 387/460\n",
      "sampling trajectories for possible start locations: 388/460\n",
      "sampling trajectories for possible start locations: 389/460\n",
      "sampling trajectories for possible start locations: 390/460\n",
      "sampling trajectories for possible start locations: 391/460\n",
      "sampling trajectories for possible start locations: 392/460\n",
      "sampling trajectories for possible start locations: 393/460\n",
      "sampling trajectories for possible start locations: 394/460\n",
      "sampling trajectories for possible start locations: 395/460\n",
      "sampling trajectories for possible start locations: 396/460\n",
      "sampling trajectories for possible start locations: 397/460\n",
      "sampling trajectories for possible start locations: 398/460\n",
      "sampling trajectories for possible start locations: 399/460\n",
      "sampling trajectories for possible start locations: 400/460\n",
      "sampling trajectories for possible start locations: 401/460\n",
      "sampling trajectories for possible start locations: 402/460\n",
      "sampling trajectories for possible start locations: 403/460\n",
      "sampling trajectories for possible start locations: 404/460\n",
      "sampling trajectories for possible start locations: 405/460\n",
      "sampling trajectories for possible start locations: 406/460\n",
      "sampling trajectories for possible start locations: 407/460\n",
      "sampling trajectories for possible start locations: 408/460\n",
      "sampling trajectories for possible start locations: 409/460\n",
      "sampling trajectories for possible start locations: 410/460\n",
      "sampling trajectories for possible start locations: 411/460\n",
      "sampling trajectories for possible start locations: 412/460\n",
      "sampling trajectories for possible start locations: 413/460\n",
      "sampling trajectories for possible start locations: 414/460\n",
      "sampling trajectories for possible start locations: 415/460\n",
      "sampling trajectories for possible start locations: 416/460\n",
      "sampling trajectories for possible start locations: 417/460\n",
      "sampling trajectories for possible start locations: 418/460\n",
      "sampling trajectories for possible start locations: 419/460\n",
      "sampling trajectories for possible start locations: 420/460\n",
      "sampling trajectories for possible start locations: 421/460\n",
      "sampling trajectories for possible start locations: 422/460\n",
      "sampling trajectories for possible start locations: 423/460\n",
      "sampling trajectories for possible start locations: 424/460\n",
      "sampling trajectories for possible start locations: 425/460\n",
      "sampling trajectories for possible start locations: 426/460\n",
      "sampling trajectories for possible start locations: 427/460\n",
      "sampling trajectories for possible start locations: 428/460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 429/460\n",
      "sampling trajectories for possible start locations: 430/460\n",
      "sampling trajectories for possible start locations: 431/460\n",
      "sampling trajectories for possible start locations: 432/460\n",
      "sampling trajectories for possible start locations: 433/460\n",
      "sampling trajectories for possible start locations: 434/460\n",
      "sampling trajectories for possible start locations: 435/460\n",
      "sampling trajectories for possible start locations: 436/460\n",
      "sampling trajectories for possible start locations: 437/460\n",
      "sampling trajectories for possible start locations: 438/460\n",
      "sampling trajectories for possible start locations: 439/460\n",
      "sampling trajectories for possible start locations: 440/460\n",
      "sampling trajectories for possible start locations: 441/460\n",
      "sampling trajectories for possible start locations: 442/460\n",
      "sampling trajectories for possible start locations: 443/460\n",
      "sampling trajectories for possible start locations: 444/460\n",
      "sampling trajectories for possible start locations: 445/460\n",
      "sampling trajectories for possible start locations: 446/460\n",
      "sampling trajectories for possible start locations: 447/460\n",
      "sampling trajectories for possible start locations: 448/460\n",
      "sampling trajectories for possible start locations: 449/460\n",
      "sampling trajectories for possible start locations: 450/460\n",
      "sampling trajectories for possible start locations: 451/460\n",
      "sampling trajectories for possible start locations: 452/460\n",
      "sampling trajectories for possible start locations: 453/460\n",
      "sampling trajectories for possible start locations: 454/460\n",
      "sampling trajectories for possible start locations: 455/460\n",
      "sampling trajectories for possible start locations: 456/460\n",
      "sampling trajectories for possible start locations: 457/460\n",
      "sampling trajectories for possible start locations: 458/460\n",
      "sampling trajectories for possible start locations: 459/460\n",
      "sampling trajectories for possible start locations: 460/460\n"
     ]
    }
   ],
   "source": [
    "from data_generator.human_mcm import Grid_HMM\n",
    "from data_generator.astar_ped_sim.astar_traj_generator import sample_trajectories\n",
    "\n",
    "res = .2\n",
    "trajs = sample_trajectories(map_, 5, mode='transverse', verbose=True, diagonal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.occ_map_utils import plot_trajectories\n",
    "fig = plt.figure()\n",
    "for traj in trajs:\n",
    "    plot_trajectories([traj], map_, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 11],\n",
       "       [ 0, 12],\n",
       "       [ 0, 13],\n",
       "       [ 1, 13],\n",
       "       [ 2, 13]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add transitions of 1/2300 trajectory to the mcm.\n",
      "Add transitions of 101/2300 trajectory to the mcm.\n",
      "Add transitions of 201/2300 trajectory to the mcm.\n",
      "Add transitions of 301/2300 trajectory to the mcm.\n",
      "Add transitions of 401/2300 trajectory to the mcm.\n",
      "Add transitions of 501/2300 trajectory to the mcm.\n",
      "Add transitions of 601/2300 trajectory to the mcm.\n",
      "Add transitions of 701/2300 trajectory to the mcm.\n",
      "Add transitions of 801/2300 trajectory to the mcm.\n",
      "Add transitions of 901/2300 trajectory to the mcm.\n",
      "Add transitions of 1001/2300 trajectory to the mcm.\n",
      "Add transitions of 1101/2300 trajectory to the mcm.\n",
      "Add transitions of 1201/2300 trajectory to the mcm.\n",
      "Add transitions of 1301/2300 trajectory to the mcm.\n",
      "Add transitions of 1401/2300 trajectory to the mcm.\n",
      "Add transitions of 1501/2300 trajectory to the mcm.\n",
      "Add transitions of 1601/2300 trajectory to the mcm.\n",
      "Add transitions of 1701/2300 trajectory to the mcm.\n",
      "Add transitions of 1801/2300 trajectory to the mcm.\n",
      "Add transitions of 1901/2300 trajectory to the mcm.\n",
      "Add transitions of 2001/2300 trajectory to the mcm.\n",
      "Add transitions of 2101/2300 trajectory to the mcm.\n",
      "Add transitions of 2201/2300 trajectory to the mcm.\n"
     ]
    }
   ],
   "source": [
    "diagonal = False\n",
    "conditional = False\n",
    "mcm = Grid_HMM(np.array(map_.shape).astype(int))\n",
    "for idx, trajectory in enumerate(trajs):\n",
    "    if idx % 100 == 0:\n",
    "        print(\"Add transitions of {}/{} trajectory to the mcm.\".format(idx+1, len(trajs)))\n",
    "    #trajectory = np.round((trajectory / res) - 0.5).astype(int)\n",
    "    #print(str(trajectory))\n",
    "    for t in range(trajectory.shape[0] - 2):\n",
    "        # give first cell seven prior locations\n",
    "        # and add them to transitions\n",
    "        if t == 0:\n",
    "            first_cell = trajectory[0, :]\n",
    "            second_cell = trajectory[1, :]\n",
    "            velocities =  [[0, 1], [1, 0], [0, -1], [-1, 0],\n",
    "                      [1, 1], [1, -1], [-1, 1], [-1, -1]]\n",
    "            if not diagonal:\n",
    "                velocities = velocities[:4]\n",
    "            prior_cells = [[first_cell[0]+i, first_cell[1]+j]\n",
    "                           for i, j in velocities]\n",
    "            for cell in prior_cells:\n",
    "                if cell[0] != second_cell[0] or cell[1] != second_cell[1]:\n",
    "                    mcm.add_transition(cell, first_cell, second_cell)\n",
    "\n",
    "        from_ = trajectory[t, :]\n",
    "        current = trajectory[t + 1, :]\n",
    "        to = trajectory[t + 2, :]\n",
    "        mcm.add_transition(from_, current, to)\n",
    "\n",
    "transition_probs = mcm.get_transition_probs(conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  4]\n",
      "[[ 0.          0.20547945  0.        ]\n",
      " [ 0.26712329  0.          0.26027397]\n",
      " [ 0.          0.26712329  0.        ]]\n",
      "1.0\n",
      "[20  1]\n",
      "[[ 0.          0.16666667  0.        ]\n",
      " [ 0.16666667  0.          0.16666667]\n",
      " [ 0.          0.5         0.        ]]\n",
      "1.0\n",
      "[20  2]\n",
      "[[ 0.          0.2826087   0.        ]\n",
      " [ 0.10869565  0.          0.10869565]\n",
      " [ 0.          0.5         0.        ]]\n",
      "1.0\n",
      "[20  3]\n",
      "[[ 0.          0.14935065  0.        ]\n",
      " [ 0.32467532  0.          0.32467532]\n",
      " [ 0.          0.2012987   0.        ]]\n",
      "1.0\n",
      "[20  4]\n",
      "[[ 0.          0.20547945  0.        ]\n",
      " [ 0.26712329  0.          0.26027397]\n",
      " [ 0.          0.26712329  0.        ]]\n",
      "1.0\n",
      "[20  5]\n",
      "[[ 0.          0.0376569   0.        ]\n",
      " [ 0.46025105  0.          0.48849372]\n",
      " [ 0.          0.01359833  0.        ]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "transition_counts = mcm.get_transition_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 8)\n",
      "[[[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  1.  0.]\n",
      "   [ 1.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.  0.]\n",
      "   [ 1.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  1.  0.]\n",
      "   [ 0.  0.  1.]\n",
      "   [ 0.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 1.  0.  1.]\n",
      "   [ 0.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]]]]\n",
      "[[ 0.  2.  0.]\n",
      " [ 2.  0.  3.]\n",
      " [ 0.  3.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.random.randint(0, 32), np.random.randint(0, 32)\n",
    "print(x, y)\n",
    "print(transition_counts[x, y])\n",
    "print(np.sum(transition_counts[x, y], axis=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 21)\n",
      "[[[[ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]]\n",
      "\n",
      "  [[ 0.   0.1  0. ]\n",
      "   [ 0.   0.   0.1]\n",
      "   [ 0.   0.   0. ]]\n",
      "\n",
      "  [[ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]]]\n",
      "\n",
      "\n",
      " [[[ 0.   0.1  0. ]\n",
      "   [ 0.1  0.   0. ]\n",
      "   [ 0.   0.1  0. ]]\n",
      "\n",
      "  [[ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]]\n",
      "\n",
      "  [[ 0.   0.1  0. ]\n",
      "   [ 0.   0.   0.1]\n",
      "   [ 0.   0.   0. ]]]\n",
      "\n",
      "\n",
      " [[[ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]]\n",
      "\n",
      "  [[ 0.   0.   0. ]\n",
      "   [ 0.1  0.   0.1]\n",
      "   [ 0.   0.1  0. ]]\n",
      "\n",
      "  [[ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]\n",
      "   [ 0.   0.   0. ]]]]\n",
      "[[ 0.   0.2  0. ]\n",
      " [ 0.3  0.   0.2]\n",
      " [ 0.   0.3  0. ]]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.random.randint(0, 32), np.random.randint(0, 32)\n",
    "print(x, y)\n",
    "print(transition_probs[x, y])\n",
    "print(np.sum(transition_probs[x, y], axis=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories: 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  5]\n",
      "[[ 0.          0.0376569   0.        ]\n",
      " [ 0.46025105  0.          0.48849372]\n",
      " [ 0.          0.01359833  0.        ]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(omega=0.05,\n",
    "              noise_var=0.5,\n",
    "              extent=7,\n",
    "              verbose=False)\n",
    "\n",
    "#model_name = '23_ALL_MAPS_EIGHT_DIRECTIONS'\n",
    "model_name = '20_ALL_MAPS_W_MASK'\n",
    "\n",
    "bofum_2 = conditionalBOFUM(map_, model_name,\n",
    "                                   name = 'BOFUM with n. o. as acceleration',\n",
    "                                   simulated_data=True,\n",
    "                                   with_reachability=True,\n",
    "                                   acceleration_interpretation=True,\n",
    "                                   nn_probs=None,\n",
    "                                   force_predict=True,\n",
    "                                   conditional=conditional,\n",
    "                                   config=config,\n",
    "                                   **kwargs)\n",
    "\n",
    "bofum_2.nn_probs = transition_probs\n",
    "distances, trajs = bofum_2.initialize(num_targets=1, num_steps=20, diagonal=False)\n",
    "\n",
    "from propagation.animation import Plot\n",
    "fig_6 = plt.figure(figsize=(5, 5))\n",
    "fig_7 = plt.figure(figsize=(6, 5))\n",
    "fig_8 = plt.figure(figsize=(6, 5))\n",
    "\n",
    "map_axes_2 = fig_6.add_subplot(111)\n",
    "plot_2 = Plot(map_axes_2, bofum_2.map, bofum_2.map_res)\n",
    "fig_6.canvas.mpl_connect('button_press_event', lambda event: onclick(event, bofum_2, fig_6, fig_7, fig_8, plot_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate transition_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.occ_map_utils import load_map, show_map, plot_occ_map, plot_trajectories, free_space\n",
    "\n",
    "simple_map, _, _ = load_map(\"/home/ful7rng/projects/transition/data_validation/maps/simple_map/thresholded_20.png\")\n",
    "tran_map = np.load(\"/home/ful7rng/projects/transition/data_validation/transition_maps/simple_map/astar_cost_transverse_6_20_5/astar_cost_transverse_6_20_5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directions = {0: 'UP', 1: 'RIGHT', 2: 'DOWN', 3: 'LEFT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-442a2631ee64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_occ_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mocc_map_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'P[{}|{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "n = 0\n",
    "fig = plt.figure()\n",
    "show_map(simple_map, resolution=0.2)\n",
    "plot_occ_map(tran_map[:,:,m,n], simple_map, occ_map_res=0.2)\n",
    "fig.suptitle('P[{}|{}]'.format(directions[m], directions[n]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel_multi_index((2, 1), (3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_map_and_probs(map_, transition_probs_1):\n",
    "\n",
    "    kwargs = dict(omega=0.05,\n",
    "                  noise_var=0.5,\n",
    "                  extent=7,\n",
    "                  verbose=False)\n",
    "\n",
    "    #model_name = '23_ALL_MAPS_EIGHT_DIRECTIONS'\n",
    "    model_name = '20_ALL_MAPS_W_MASK'\n",
    "\n",
    "    bofum_2 = conditionalBOFUM(map_, model_name,\n",
    "                                       name = 'BOFUM with n. o. as acceleration',\n",
    "                                       simulated_data=True,\n",
    "                                       with_reachability=True,\n",
    "                                       acceleration_interpretation=True,\n",
    "                                       nn_probs=None,\n",
    "                                       force_predict=True,\n",
    "                                       conditional=conditional,\n",
    "                                       config=config,\n",
    "                                       **kwargs)\n",
    "\n",
    "    bofum_2.conditional_probs = transition_probs_1\n",
    "    distances, trajs = bofum_2.initialize(num_targets=1, num_steps=20, diagonal=False)\n",
    "\n",
    "    from propagation.animation import Plot\n",
    "    fig_6 = plt.figure(figsize=(5, 5))\n",
    "    fig_7 = plt.figure(figsize=(6, 5))\n",
    "    fig_8 = plt.figure(figsize=(6, 5))\n",
    "\n",
    "    map_axes_2 = fig_6.add_subplot(111)\n",
    "    plot_2 = Plot(map_axes_2, bofum_2.map, bofum_2.map_res)\n",
    "    fig_6.canvas.mpl_connect('button_press_event', lambda event: onclick(event, bofum_2, fig_6, fig_7, fig_8, plot_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flip left/right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip(probs):\n",
    "    # spatial dimensions of numpy array flip updown\n",
    "    probs = np.flip(probs, axis=0)\n",
    "    # velocity directions of left/right change to right/left\n",
    "    probs = np.flip(probs, axis=2)\n",
    "    probs = np.flip(probs, axis=4)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_1 = np.flipud(map_.copy())\n",
    "trans_probs_1 = flip(transition_probs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories: 1/1\n",
      "[25 14]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[14 10]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[15  9]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[16  9]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[17  9]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[17 10]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[25 16]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[ 6 16]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[ 6 16]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[12 11]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[12  8]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[19  8]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "show_map_and_probs(map_1, trans_probs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rotate 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(probs, k):\n",
    "    \"\"\" Rotate the probs 90 degrees counter-clockwise k times.\n",
    "\n",
    "    Note that directions of probabilities change after rotations. For example, if rotate once,\n",
    "    the probability of P{left|down} changes to P{down|right}.\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return probs\n",
    "\n",
    "    # spatial dimensions rotate counter-clockwise\n",
    "    probs = np.rot90(probs, k)\n",
    "    # velocitiy dimensions rotate clockwise\n",
    "    probs = np.rot90(probs, k, (2, 3))\n",
    "    probs = np.rot90(probs, k, (4, 5))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_2 = np.rot90(map_.copy(), k)\n",
    "trans_probs_2 = rotate(transition_probs.copy(), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories: 1/1\n",
      "[ 7 14]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[17  7]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[14  9]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[24 14]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[21 14]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[21 15]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[22 15]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n",
      "[22 14]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "show_map_and_probs(map_2, trans_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.expand_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check number of probs from nn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diagonal = False\n",
    "if diagonal:\n",
    "    velocities = [[0, 1], [1, 0], [0, -1], [-1, 0],\n",
    "                  [1, 1], [1, -1], [-1, 1], [-1, -1]]\n",
    "else:\n",
    "    velocities = [[0, 1], [1, 0], [0, -1], [-1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_backward_vel(v1, v2):\n",
    "    backward_v1 = [-v2[0], -v2[1]]\n",
    "    backward_v2 = [-v1[0], -v1[1]]\n",
    "    return backward_v1, backward_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude :[0, 1]\n",
      "exclude :[1, 0]\n",
      "exclude :[0, -1]\n",
      "exclude :[-1, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vs = []\n",
    "idxs = []\n",
    "for v1 in velocities:\n",
    "    for v2 in velocities:\n",
    "        idx1 = Grid_HMM.two_d_vel_to_idx(v1)\n",
    "        idx2 = Grid_HMM.two_d_vel_to_idx(v2)\n",
    "        if v1 == [-v2[0], -v2[1]]:\n",
    "            print(\"exclude :\" + str(v1))\n",
    "            continue\n",
    "        backward_v1, backward_v2 = get_backward_vel(v1, v2) \n",
    "        b_idx1 = Grid_HMM.two_d_vel_to_idx(backward_v1)\n",
    "        b_idx2 = Grid_HMM.two_d_vel_to_idx(backward_v2)\n",
    "        v1_, v2_, backward_v1_, backward_v2_ = map(lambda foo: tuple(foo), [v1, v2, backward_v1, backward_v2])\n",
    "        idx1_, idx2_, b_idx1_, b_idx2_ = map(lambda foo: tuple(foo), [idx1, idx2, b_idx1, b_idx2])\n",
    "        if (v1_ + v2_) not in vs and (backward_v1_ + backward_v2_) not in vs:\n",
    "            vs.append((v1_ + v2_))\n",
    "        if (idx1_ + idx2_) not in idxs and (b_idx1_ + b_idx2_) not in idxs:\n",
    "            idxs.append((idx1_ + idx2_))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 0, 1),\n",
       " (0, 1, 1, 0),\n",
       " (0, 1, -1, 0),\n",
       " (1, 0, 0, 1),\n",
       " (1, 0, 1, 0),\n",
       " (0, -1, 1, 0)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 1, 2),\n",
       " (1, 2, 2, 1),\n",
       " (1, 2, 0, 1),\n",
       " (2, 1, 1, 2),\n",
       " (2, 1, 2, 1),\n",
       " (1, 0, 2, 1)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (idx1_0, idx1_1, idx2_0, idx2_1) in idxs:\n",
    "    idx1 = (idx1_0, idx1_1)\n",
    "    idx2 = (idx2_0, idx2_1)\n",
    "    v1 = Grid_HMM.two_d_idx_to_vel(idx1)\n",
    "    v2 = Grid_HMM.two_d_idx_to_vel(idx2)\n",
    "    b_v1, b_v2 = get_backward_vel(v1, v2)\n",
    "    b_idx1 = Grid_HMM.two_d_vel_to_idx(b_v1)\n",
    "    b_idx2 = Grid_HMM.two_d_vel_to_idx(b_v2)\n",
    "    idx_4d = idx1 + idx2\n",
    "    b_idx_4d = b_idx1 + b_idx2\n",
    "    for idx_ in np.ndindex(transition_probs.shape[:2]):\n",
    "        assert transition_probs[idx_+idx_4d] == transition_probs[idx_+b_idx_4d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for idx_ in np.ndindex(transition_probs.shape[:2]):\n",
    "    sum_ = 0\n",
    "    for idx in idxs:\n",
    "        sum_ += transition_probs[idx_+idx]\n",
    "    print(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 3, 5)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probs.shape[:-2] + (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_probs.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of Net failed: Traceback (most recent call last):\n",
      "  File \"/local/home/ful7rng/.anaconda/envs/ful/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ImportError: No module named Net\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82944"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_probs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of Net failed: Traceback (most recent call last):\n",
      "  File \"/local/home/ful7rng/.anaconda/envs/ful/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ImportError: No module named Net\n",
      "]\n",
      "[autoreload of propagation.bofum failed: Traceback (most recent call last):\n",
      "  File \"/local/home/ful7rng/.anaconda/envs/ful/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "NameError: name 'config' is not defined\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3, 3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-245-70faed3677bb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-245-70faed3677bb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x[:, :, *(4, 4)].shape\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x[:, :, *(4, 4)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-249-817642c211bb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-249-817642c211bb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x[:, :, *[4, 4]].shape\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x[:, :, *[4, 4]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of propagation.bofum failed: Traceback (most recent call last):\n",
      "  File \"/local/home/ful7rng/.anaconda/envs/ful/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "NameError: name 'config' is not defined\n",
      "]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-d4c8e9c50b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "np.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a class, type, or tuple of classes and types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2abe96b1f2ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a class, type, or tuple of classes and types"
     ]
    }
   ],
   "source": [
    "isinstance(config, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### check trajectory on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "config_path = '/local/home/ful7rng/projects/transition/config_diagonal_True_conditional_True.py'\n",
    "cf = imp.load_source('config', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_map\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "map_name = random.sample(cf.training_maps, 1)[0]\n",
    "print(map_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/home/ful7rng/projects/transition/data/maps/simple_map/thresholded_20.png\n",
      "/local/home/ful7rng/projects/transition/data_diagonal_true_conditioanl_true/trajectories/simple_map/astar_cost_diagonal_transverse_0_10_5/astar_cost_diagonal_transverse_0_10_5.npy\n"
     ]
    }
   ],
   "source": [
    "map_path = cf.map_folder + '/' + map_name + '/thresholded_20.png'\n",
    "trajectory_path = cf.data_folder+'/trajectories/'+map_name+'/'+cf.algo_str+'/'+cf.algo_str+'.npy'\n",
    "probs_path = cf.data_folder+'/transition_maps/'+map_name+'/'+cf.algo_str+'/'+cf.algo_str+'.npy'\n",
    "print(map_path)\n",
    "print(trajectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4000 trajs\n"
     ]
    }
   ],
   "source": [
    "from utils.occ_map_utils import load_map, show_map\n",
    "map_, _, _ = load_map(map_path)\n",
    "trajs = np.load(trajectory_path)\n",
    "rescale = lambda traj: np.round((traj / .2) - 0.5).astype(int)\n",
    "trajs_rescaled = map(rescale, trajs)\n",
    "probs = np.load(probs_path)\n",
    "print(\"total %d trajs\" % len(trajs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 46]\n",
      "[28, 46]\n",
      "Found 0 trajs going through here\n",
      "[21 45]\n",
      "[21, 45]\n",
      "Found 116 trajs going through here\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "map_axes = fig.add_subplot(111)\n",
    "plot = Plot(map_axes, map_, .2)\n",
    "fig_1 = plt.figure(figsize=(5, 5))\n",
    "fig.canvas.mpl_connect('button_press_event', lambda event: onclick_traj(event, fig, plot, fig_1, trajs_rescaled, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "def onclick_traj(event,fig, plot, fig_1, raw_trajs, probs, **kwargs):\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(plot.lines)):\n",
    "            plot.axes.lines.remove(plot.lines[i])\n",
    "    except AttributeError, ValueError:\n",
    "        pass\n",
    "\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    coords = np.floor(np.array([ix, iy]) / 0.2).astype(int)\n",
    "    print(coords)\n",
    "    \n",
    "    clicked = np.zeros_like(map_)\n",
    "    x, y = coords[0], coords[1]\n",
    "    clicked[x, y] = 1\n",
    "    plot.set_axes_data(\"occupancy_axes\", clicked)\n",
    "    \n",
    "    w, h = kwargs.get('w', 0)//2, kwargs.get('h', 0)//2\n",
    "    x_padded, y_padded = x+w, y+h\n",
    "    print([x_padded, y_padded])\n",
    "    trajs_here = []\n",
    "    for idx, traj in enumerate(raw_trajs):\n",
    "        if [x_padded, y_padded] in traj.tolist():\n",
    "            traj_ = raw_trajs[idx] - np.array([w, h])\n",
    "            trajs_here.append(rescale_trajectory(traj_, .2))\n",
    "    print(\"Found %d trajs going through here\" % len(trajs_here))\n",
    "    colors = cm.Dark2(np.linspace(0, 1, len(trajs_here)))\n",
    "    plot.lines = map(lambda color: plot.axes.add_line(Line2D([], [], zorder=13, color=color)), colors)\n",
    "    for idx, line in enumerate(plot.lines):\n",
    "        xs, ys = trajs_here[idx].T[0], trajs_here[idx].T[1]\n",
    "#         if idx <= 5:\n",
    "#             print(trajs_here[idx])\n",
    "        line.set_data(xs, ys)\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    fig_1.clear()\n",
    "    plot_4d_tensor(probs[x, y], fig=fig_1)\n",
    "    fig_1.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "from utils import nd_gaussian\n",
    "def onclick_traj_random(event,fig, plot, fig_1, raw_trajs, probs, **kwargs):\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(plot.lines)):\n",
    "            plot.axes.lines.remove(plot.lines[i])\n",
    "    except AttributeError, ValueError:\n",
    "        pass\n",
    "\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    coords = np.floor(np.array([ix, iy]) / 0.2).astype(int)\n",
    "    print(coords)\n",
    "    \n",
    "    clicked = np.zeros_like(map_)\n",
    "    x, y = coords[0], coords[1]\n",
    "    clicked[x, y] = 1\n",
    "    plot.set_axes_data(\"occupancy_axes\", clicked)\n",
    "    \n",
    "    g_len = 300\n",
    "    gaussian_res = float(g_len) / 32\n",
    "    center = [round((x+.5) * gaussian_res), round((y+.5) * gaussian_res)]\n",
    "    gaussian = nd_gaussian([g_len, g_len], center, cov=14)\n",
    "    plot.set_axes_data(\"gaussian_axes\", gaussian)\n",
    "    \n",
    "    w, h = kwargs.get('w', 0)//2, kwargs.get('h', 0)//2\n",
    "    x_padded, y_padded = x+w, y+h\n",
    "    print([x_padded, y_padded])\n",
    "    trajs_here = []\n",
    "    for idx, traj in enumerate(raw_trajs):\n",
    "        if [x_padded, y_padded] in traj.tolist():\n",
    "            traj_ = raw_trajs[idx] - np.array([w, h])\n",
    "            trajs_here.append(rescale_trajectory(traj_, .2))\n",
    "    print(\"Found %d trajs going through here\" % len(trajs_here))\n",
    "    idx = np.random.randint(len(trajs_here))\n",
    "    print(\"Take random traj at idx %d\" % idx)\n",
    "    idx = 3\n",
    "    colors = cm.Dark2(np.linspace(0, 1, len(trajs_here)))\n",
    "    plot.lines = [plot.axes.add_line(Line2D([], [], zorder=13, color=colors[idx]))]\n",
    "\n",
    "    xs, ys = trajs_here[idx].T[0], trajs_here[idx].T[1]\n",
    "#         if idx <= 5:\n",
    "#             print(trajs_here[idx])\n",
    "    plot.lines[0].set_data(xs, ys)\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    fig_1.clear()\n",
    "    plot_4d_tensor(probs[x, y], fig=fig_1)\n",
    "    fig_1.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 48],\n",
       "       [ 4, 48],\n",
       "       [ 5, 47],\n",
       "       [ 5, 46],\n",
       "       [ 5, 45]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### traj generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file: /home/ful7rng/projects/transition/data/selected_scenes_from_100_11.npy\n",
      "Found 1655 scenes in total\n",
      "42\n",
      "12000000\n",
      "Found 1160.000000 scenes (= 70.09%) whose interval is in range (3.50, 1000000.00)\n",
      "Found 0 scenes (= 0.000%) whose interval does not match number of hits.\n",
      "514\n",
      "(17, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "fname = '/home/ful7rng/projects/transition/data/selected_scenes_from_100_11.npy'\n",
    "sample_rate = 3\n",
    "scenes = get_scenes(random_file=False,\n",
    "                  min_time_interval=3.5,\n",
    "                  max_time_interval=1e6,\n",
    "                  sample_rate=sample_rate,\n",
    "                  file_name=fname)[0]\n",
    "idx = np.random.choice(np.arange(len(scenes)))\n",
    "print(idx)\n",
    "scene = scenes[idx]\n",
    "map_ = scene.static_map\n",
    "print(scene.hits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3e1410210>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_map(scenes[514].static_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.scene_utils.SceneAnimation at 0x7fe3ffb38190>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate_scenes([scene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_T_section(size):\n",
    "    map_size = size\n",
    "    map_ = np.ones((map_size, map_size), dtype=bool)\n",
    "    lane_length = size // 2\n",
    "\n",
    "    for j in range(map_size / 2):\n",
    "        map_[j + 1:j + lane_length + 1, j] = 0\n",
    "    for j in range(map_size / 2, map_size):\n",
    "        map_[map_size - j:map_size - j + lane_length, j] = 0\n",
    "    for j in range(map_size / 2 - lane_length / 2, map_size / 2 + lane_length / 2 + 1):\n",
    "        map_[map_size / 2:map_size, j] = 0\n",
    "    x, y = map_size - map_size / 4, map_size / 2\n",
    "    return map_, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_, x, y = make_T_section(91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, h = map_.shape\n",
    "padded_map = np.pad(map_, ((w//2, w//2), (h//2, h//2)), mode='edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_cost_map(map_):\n",
    "    collision_cost = 2000\n",
    "\n",
    "    blur1_width = 5\n",
    "    blurred_map1 = cv2.GaussianBlur(map_.astype(float),\n",
    "                                   (blur1_width, blur1_width), 0)\n",
    "    blur2_width = 11\n",
    "    blurred_map2 = cv2.GaussianBlur(map_.astype(float),\n",
    "                                   (blur2_width, blur2_width), 0)\n",
    "    blur1_cost = 2\n",
    "    blur2_cost = 1\n",
    "    cost_map = collision_cost * map_.astype(float) + \\\n",
    "               blur1_cost * blurred_map1 + blur2_cost * blurred_map2\n",
    "    return cost_map\n",
    "\n",
    "def sample_trajs(padded_map, map_, w, h, num_trajectories, diagonal=False, mode='random', verbose=True):\n",
    "    \n",
    "    trajectories = []\n",
    "    \n",
    "    cost_map = get_cost_map(padded_map)\n",
    "    \n",
    "    start_locations = np.array(np.where(np.logical_not(map_))).T\n",
    "    start_locations += np.array([w//2, h//2])\n",
    "\n",
    "    if mode == 'traverse':\n",
    "        num_locations = len(start_locations)\n",
    "        for idx, start in enumerate(start_locations):\n",
    "            if verbose and idx % 1 == 0:\n",
    "                print('sampling trajectories for possible start locations: {}/{}'.format(\n",
    "                    idx + 1, num_locations))\n",
    "                x, y = start\n",
    "#                 center_map = np.ones_like(padded_map)\n",
    "#                 center_map[x-w//2:x+w//2, y-h//2:y+h//2] = padded_map[x-w//2:x+w//2, y-h//2:y+h//2]\n",
    "                center_map = padded_map\n",
    "                trajectories_ = _sample_trajectories(start, center_map, cost_map,\n",
    "                                                     num_trajectories, diagonal)\n",
    "                if trajectories_ is not None:\n",
    "                    trajectories += trajectories_\n",
    "    elif mode == 'random':\n",
    "        for ix in range(int(num_trajectories)):\n",
    "            if verbose and ix % 10 == 0:\n",
    "                print('sampling trajectories: {}/{}'.format(\n",
    "                    ix + 1, num_trajectories))\n",
    "            # loop to find valid path\n",
    "            while True:\n",
    "                start = random.sample(start_locations, 1)[0]\n",
    "                x, y = start\n",
    "                center_map = padded_map\n",
    "#                 center_map = np.ones_like(padded_map)\n",
    "#                 center_map[x-w//2:x+w//2, y-h//2:y+h//2] = padded_map[x-w//2:x+w//2, y-h//2:y+h//2]\n",
    "                print(\"start is :{}\".format(start))\n",
    "                trajectory = _sample_trajectories(start, center_map, cost_map, 1, diagonal)\n",
    "                if trajectory is not None and len(trajectory) > 0:\n",
    "                    break\n",
    "            trajectories += trajectory\n",
    "\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_sg_random(goal_arr):\n",
    "    # get list of pixels in that area\n",
    "    goals = np.array(np.where(free_space(goal_arr))).T.tolist()\n",
    "    # sample random pixel\n",
    "    if goals:\n",
    "        goal = random.sample(goals, 1)\n",
    "        return np.array((goal[0]))\n",
    "    # in case there is no possible sample result\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "import cv2\n",
    "\n",
    "from data_generator.multi_agent_planning.scripts.pyastar import astar_path\n",
    "def _sample_trajectories(start, map_arr, cost_map, num, diagonal=True):\n",
    "    \"\"\" Try to sample num trajectories given a valid start and cost map. \"\"\"\n",
    "\n",
    "    # a_star_grid = AStarGrid(cost_map, diagonal=diagonal)\n",
    "\n",
    "    trajectories = []\n",
    "    # get wall locations\n",
    "    walls = set([tuple(loc) for loc in np.array(np.where(map_arr)).T.tolist()])\n",
    "\n",
    "    ends = []\n",
    "    current_have = 0\n",
    "    tried = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if current_have >= num:\n",
    "            break\n",
    "\n",
    "        if tried >= 10 * num:\n",
    "            break\n",
    "\n",
    "        end = sample_sg_random(map_arr)\n",
    "\n",
    "        if end is None:\n",
    "            # return None to indicate there is no possible end\n",
    "            # therefore no possible trajectory for this start\n",
    "            return None\n",
    "\n",
    "\n",
    "        if list(end) in ends:\n",
    "            tried += 1\n",
    "            continue\n",
    "\n",
    "        #t1 = time.time()\n",
    "\n",
    "        trajectory, values = astar_path(cost_map.astype('float32'), start, end, 1, diagonal)\n",
    "        \n",
    "        if len(trajectory) == 0:\n",
    "            trajectory = None\n",
    "        else:\n",
    "            trajectory = np.insert(trajectory, 0, end, axis=0)[::-1]\n",
    "        \n",
    "\n",
    "        if trajectory is not None:\n",
    "            # check whether trajectory goes through walls\n",
    "            traj_traces = [tuple(loc) for loc in trajectory]\n",
    "            if len(walls.intersection(traj_traces)) > 0:\n",
    "                trajectory = None\n",
    "\n",
    "\n",
    "\n",
    "        if trajectory is not None:\n",
    "            trajectories.append(np.array(trajectory))\n",
    "            ends.append(list(end))\n",
    "            current_have += 1\n",
    "                # print(\"got one traj\")\n",
    "\n",
    "        tried += 1\n",
    "\n",
    "    return trajectories\n",
    "\n",
    "def rescale_trajectory(trajectory, resolution):\n",
    "    # scale path to real world extent\n",
    "    return np.array(trajectory + np.array([0.5] * 2)[None, :]) * resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "def onclick_generate_traj(event, fig, plot):\n",
    "    print(\"clicked\")\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(plot.lines)):\n",
    "            plot.axes.lines.remove(plot.lines[i])\n",
    "    except AttributeError, ValueError:\n",
    "        pass\n",
    "\n",
    "    trajs_rescaled = []\n",
    "    trajs = sample_trajs(padded_map, map_, w, h, 5, diagonal=True, mode='random')\n",
    "    for traj in trajs:\n",
    "        trajs_rescaled.append(rescale_trajectory(traj, .2))\n",
    "        \n",
    "\n",
    "    colors = cm.Dark2(np.linspace(0, 1, len(trajs)))\n",
    "    plot.lines = map(lambda color: plot.axes.add_line(Line2D([], [], zorder=13, color=color)), colors)\n",
    "    for idx, line in enumerate(plot.lines):\n",
    "        xs, ys = trajs_rescaled[idx].T[0], trajs_rescaled[idx].T[1]\n",
    "#         if idx <= 5:\n",
    "#             print(trajs_here[idx])\n",
    "        line.set_data(xs, ys)\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n",
      "sampling trajectories: 1/5\n",
      "start is :[42 29]\n",
      "start is :[27 33]\n",
      "start is :[38 45]\n",
      "start is :[36 29]\n",
      "start is :[32 38]\n",
      "start is :[16 36]\n",
      "clicked\n",
      "sampling trajectories: 1/5\n",
      "start is :[46 33]\n",
      "start is :[47 35]\n",
      "start is :[45 19]\n",
      "start is :[39 43]\n",
      "start is :[35 22]\n"
     ]
    }
   ],
   "source": [
    "fig_1 = plt.figure(figsize=(7, 7))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "plot_1 = Plot(ax_1, padded_map, .2)\n",
    "fig_1.canvas.mpl_connect('button_press_event', lambda event: onclick_generate_traj(event, fig_1, plot_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add trajs to transitional map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 1/615\n",
      "sampling trajectories for possible start locations: 2/615\n",
      "sampling trajectories for possible start locations: 3/615\n",
      "sampling trajectories for possible start locations: 4/615\n",
      "sampling trajectories for possible start locations: 5/615\n",
      "sampling trajectories for possible start locations: 6/615\n",
      "sampling trajectories for possible start locations: 7/615\n",
      "sampling trajectories for possible start locations: 8/615\n",
      "sampling trajectories for possible start locations: 9/615\n",
      "sampling trajectories for possible start locations: 10/615\n",
      "sampling trajectories for possible start locations: 11/615\n",
      "sampling trajectories for possible start locations: 12/615\n",
      "sampling trajectories for possible start locations: 13/615\n",
      "sampling trajectories for possible start locations: 14/615\n",
      "sampling trajectories for possible start locations: 15/615\n",
      "sampling trajectories for possible start locations: 16/615\n",
      "sampling trajectories for possible start locations: 17/615\n",
      "sampling trajectories for possible start locations: 18/615\n",
      "sampling trajectories for possible start locations: 19/615\n",
      "sampling trajectories for possible start locations: 20/615\n",
      "sampling trajectories for possible start locations: 21/615\n",
      "sampling trajectories for possible start locations: 22/615\n",
      "sampling trajectories for possible start locations: 23/615\n",
      "sampling trajectories for possible start locations: 24/615\n",
      "sampling trajectories for possible start locations: 25/615\n",
      "sampling trajectories for possible start locations: 26/615\n",
      "sampling trajectories for possible start locations: 27/615\n",
      "sampling trajectories for possible start locations: 28/615\n",
      "sampling trajectories for possible start locations: 29/615\n",
      "sampling trajectories for possible start locations: 30/615\n",
      "sampling trajectories for possible start locations: 31/615\n",
      "sampling trajectories for possible start locations: 32/615\n",
      "sampling trajectories for possible start locations: 33/615\n",
      "sampling trajectories for possible start locations: 34/615\n",
      "sampling trajectories for possible start locations: 35/615\n",
      "sampling trajectories for possible start locations: 36/615\n",
      "sampling trajectories for possible start locations: 37/615\n",
      "sampling trajectories for possible start locations: 38/615\n",
      "sampling trajectories for possible start locations: 39/615\n",
      "sampling trajectories for possible start locations: 40/615\n",
      "sampling trajectories for possible start locations: 41/615\n",
      "sampling trajectories for possible start locations: 42/615\n",
      "sampling trajectories for possible start locations: 43/615\n",
      "sampling trajectories for possible start locations: 44/615\n",
      "sampling trajectories for possible start locations: 45/615\n",
      "sampling trajectories for possible start locations: 46/615\n",
      "sampling trajectories for possible start locations: 47/615\n",
      "sampling trajectories for possible start locations: 48/615\n",
      "sampling trajectories for possible start locations: 49/615\n",
      "sampling trajectories for possible start locations: 50/615\n",
      "sampling trajectories for possible start locations: 51/615\n",
      "sampling trajectories for possible start locations: 52/615\n",
      "sampling trajectories for possible start locations: 53/615\n",
      "sampling trajectories for possible start locations: 54/615\n",
      "sampling trajectories for possible start locations: 55/615\n",
      "sampling trajectories for possible start locations: 56/615\n",
      "sampling trajectories for possible start locations: 57/615\n",
      "sampling trajectories for possible start locations: 58/615\n",
      "sampling trajectories for possible start locations: 59/615\n",
      "sampling trajectories for possible start locations: 60/615\n",
      "sampling trajectories for possible start locations: 61/615\n",
      "sampling trajectories for possible start locations: 62/615\n",
      "sampling trajectories for possible start locations: 63/615\n",
      "sampling trajectories for possible start locations: 64/615\n",
      "sampling trajectories for possible start locations: 65/615\n",
      "sampling trajectories for possible start locations: 66/615\n",
      "sampling trajectories for possible start locations: 67/615\n",
      "sampling trajectories for possible start locations: 68/615\n",
      "sampling trajectories for possible start locations: 69/615\n",
      "sampling trajectories for possible start locations: 70/615\n",
      "sampling trajectories for possible start locations: 71/615\n",
      "sampling trajectories for possible start locations: 72/615\n",
      "sampling trajectories for possible start locations: 73/615\n",
      "sampling trajectories for possible start locations: 74/615\n",
      "sampling trajectories for possible start locations: 75/615\n",
      "sampling trajectories for possible start locations: 76/615\n",
      "sampling trajectories for possible start locations: 77/615\n",
      "sampling trajectories for possible start locations: 78/615\n",
      "sampling trajectories for possible start locations: 79/615\n",
      "sampling trajectories for possible start locations: 80/615\n",
      "sampling trajectories for possible start locations: 81/615\n",
      "sampling trajectories for possible start locations: 82/615\n",
      "sampling trajectories for possible start locations: 83/615\n",
      "sampling trajectories for possible start locations: 84/615\n",
      "sampling trajectories for possible start locations: 85/615\n",
      "sampling trajectories for possible start locations: 86/615\n",
      "sampling trajectories for possible start locations: 87/615\n",
      "sampling trajectories for possible start locations: 88/615\n",
      "sampling trajectories for possible start locations: 89/615\n",
      "sampling trajectories for possible start locations: 90/615\n",
      "sampling trajectories for possible start locations: 91/615\n",
      "sampling trajectories for possible start locations: 92/615\n",
      "sampling trajectories for possible start locations: 93/615\n",
      "sampling trajectories for possible start locations: 94/615\n",
      "sampling trajectories for possible start locations: 95/615\n",
      "sampling trajectories for possible start locations: 96/615\n",
      "sampling trajectories for possible start locations: 97/615\n",
      "sampling trajectories for possible start locations: 98/615\n",
      "sampling trajectories for possible start locations: 99/615\n",
      "sampling trajectories for possible start locations: 100/615\n",
      "sampling trajectories for possible start locations: 101/615\n",
      "sampling trajectories for possible start locations: 102/615\n",
      "sampling trajectories for possible start locations: 103/615\n",
      "sampling trajectories for possible start locations: 104/615\n",
      "sampling trajectories for possible start locations: 105/615\n",
      "sampling trajectories for possible start locations: 106/615\n",
      "sampling trajectories for possible start locations: 107/615\n",
      "sampling trajectories for possible start locations: 108/615\n",
      "sampling trajectories for possible start locations: 109/615\n",
      "sampling trajectories for possible start locations: 110/615\n",
      "sampling trajectories for possible start locations: 111/615\n",
      "sampling trajectories for possible start locations: 112/615\n",
      "sampling trajectories for possible start locations: 113/615\n",
      "sampling trajectories for possible start locations: 114/615\n",
      "sampling trajectories for possible start locations: 115/615\n",
      "sampling trajectories for possible start locations: 116/615\n",
      "sampling trajectories for possible start locations: 117/615\n",
      "sampling trajectories for possible start locations: 118/615\n",
      "sampling trajectories for possible start locations: 119/615\n",
      "sampling trajectories for possible start locations: 120/615\n",
      "sampling trajectories for possible start locations: 121/615\n",
      "sampling trajectories for possible start locations: 122/615\n",
      "sampling trajectories for possible start locations: 123/615\n",
      "sampling trajectories for possible start locations: 124/615\n",
      "sampling trajectories for possible start locations: 125/615\n",
      "sampling trajectories for possible start locations: 126/615\n",
      "sampling trajectories for possible start locations: 127/615\n",
      "sampling trajectories for possible start locations: 128/615\n",
      "sampling trajectories for possible start locations: 129/615\n",
      "sampling trajectories for possible start locations: 130/615\n",
      "sampling trajectories for possible start locations: 131/615\n",
      "sampling trajectories for possible start locations: 132/615\n",
      "sampling trajectories for possible start locations: 133/615\n",
      "sampling trajectories for possible start locations: 134/615\n",
      "sampling trajectories for possible start locations: 135/615\n",
      "sampling trajectories for possible start locations: 136/615\n",
      "sampling trajectories for possible start locations: 137/615\n",
      "sampling trajectories for possible start locations: 138/615\n",
      "sampling trajectories for possible start locations: 139/615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 140/615\n",
      "sampling trajectories for possible start locations: 141/615\n",
      "sampling trajectories for possible start locations: 142/615\n",
      "sampling trajectories for possible start locations: 143/615\n",
      "sampling trajectories for possible start locations: 144/615\n",
      "sampling trajectories for possible start locations: 145/615\n",
      "sampling trajectories for possible start locations: 146/615\n",
      "sampling trajectories for possible start locations: 147/615\n",
      "sampling trajectories for possible start locations: 148/615\n",
      "sampling trajectories for possible start locations: 149/615\n",
      "sampling trajectories for possible start locations: 150/615\n",
      "sampling trajectories for possible start locations: 151/615\n",
      "sampling trajectories for possible start locations: 152/615\n",
      "sampling trajectories for possible start locations: 153/615\n",
      "sampling trajectories for possible start locations: 154/615\n",
      "sampling trajectories for possible start locations: 155/615\n",
      "sampling trajectories for possible start locations: 156/615\n",
      "sampling trajectories for possible start locations: 157/615\n",
      "sampling trajectories for possible start locations: 158/615\n",
      "sampling trajectories for possible start locations: 159/615\n",
      "sampling trajectories for possible start locations: 160/615\n",
      "sampling trajectories for possible start locations: 161/615\n",
      "sampling trajectories for possible start locations: 162/615\n",
      "sampling trajectories for possible start locations: 163/615\n",
      "sampling trajectories for possible start locations: 164/615\n",
      "sampling trajectories for possible start locations: 165/615\n",
      "sampling trajectories for possible start locations: 166/615\n",
      "sampling trajectories for possible start locations: 167/615\n",
      "sampling trajectories for possible start locations: 168/615\n",
      "sampling trajectories for possible start locations: 169/615\n",
      "sampling trajectories for possible start locations: 170/615\n",
      "sampling trajectories for possible start locations: 171/615\n",
      "sampling trajectories for possible start locations: 172/615\n",
      "sampling trajectories for possible start locations: 173/615\n",
      "sampling trajectories for possible start locations: 174/615\n",
      "sampling trajectories for possible start locations: 175/615\n",
      "sampling trajectories for possible start locations: 176/615\n",
      "sampling trajectories for possible start locations: 177/615\n",
      "sampling trajectories for possible start locations: 178/615\n",
      "sampling trajectories for possible start locations: 179/615\n",
      "sampling trajectories for possible start locations: 180/615\n",
      "sampling trajectories for possible start locations: 181/615\n",
      "sampling trajectories for possible start locations: 182/615\n",
      "sampling trajectories for possible start locations: 183/615\n",
      "sampling trajectories for possible start locations: 184/615\n",
      "sampling trajectories for possible start locations: 185/615\n",
      "sampling trajectories for possible start locations: 186/615\n",
      "sampling trajectories for possible start locations: 187/615\n",
      "sampling trajectories for possible start locations: 188/615\n",
      "sampling trajectories for possible start locations: 189/615\n",
      "sampling trajectories for possible start locations: 190/615\n",
      "sampling trajectories for possible start locations: 191/615\n",
      "sampling trajectories for possible start locations: 192/615\n",
      "sampling trajectories for possible start locations: 193/615\n",
      "sampling trajectories for possible start locations: 194/615\n",
      "sampling trajectories for possible start locations: 195/615\n",
      "sampling trajectories for possible start locations: 196/615\n",
      "sampling trajectories for possible start locations: 197/615\n",
      "sampling trajectories for possible start locations: 198/615\n",
      "sampling trajectories for possible start locations: 199/615\n",
      "sampling trajectories for possible start locations: 200/615\n",
      "sampling trajectories for possible start locations: 201/615\n",
      "sampling trajectories for possible start locations: 202/615\n",
      "sampling trajectories for possible start locations: 203/615\n",
      "sampling trajectories for possible start locations: 204/615\n",
      "sampling trajectories for possible start locations: 205/615\n",
      "sampling trajectories for possible start locations: 206/615\n",
      "sampling trajectories for possible start locations: 207/615\n",
      "sampling trajectories for possible start locations: 208/615\n",
      "sampling trajectories for possible start locations: 209/615\n",
      "sampling trajectories for possible start locations: 210/615\n",
      "sampling trajectories for possible start locations: 211/615\n",
      "sampling trajectories for possible start locations: 212/615\n",
      "sampling trajectories for possible start locations: 213/615\n",
      "sampling trajectories for possible start locations: 214/615\n",
      "sampling trajectories for possible start locations: 215/615\n",
      "sampling trajectories for possible start locations: 216/615\n",
      "sampling trajectories for possible start locations: 217/615\n",
      "sampling trajectories for possible start locations: 218/615\n",
      "sampling trajectories for possible start locations: 219/615\n",
      "sampling trajectories for possible start locations: 220/615\n",
      "sampling trajectories for possible start locations: 221/615\n",
      "sampling trajectories for possible start locations: 222/615\n",
      "sampling trajectories for possible start locations: 223/615\n",
      "sampling trajectories for possible start locations: 224/615\n",
      "sampling trajectories for possible start locations: 225/615\n",
      "sampling trajectories for possible start locations: 226/615\n",
      "sampling trajectories for possible start locations: 227/615\n",
      "sampling trajectories for possible start locations: 228/615\n",
      "sampling trajectories for possible start locations: 229/615\n",
      "sampling trajectories for possible start locations: 230/615\n",
      "sampling trajectories for possible start locations: 231/615\n",
      "sampling trajectories for possible start locations: 232/615\n",
      "sampling trajectories for possible start locations: 233/615\n",
      "sampling trajectories for possible start locations: 234/615\n",
      "sampling trajectories for possible start locations: 235/615\n",
      "sampling trajectories for possible start locations: 236/615\n",
      "sampling trajectories for possible start locations: 237/615\n",
      "sampling trajectories for possible start locations: 238/615\n",
      "sampling trajectories for possible start locations: 239/615\n",
      "sampling trajectories for possible start locations: 240/615\n",
      "sampling trajectories for possible start locations: 241/615\n",
      "sampling trajectories for possible start locations: 242/615\n",
      "sampling trajectories for possible start locations: 243/615\n",
      "sampling trajectories for possible start locations: 244/615\n",
      "sampling trajectories for possible start locations: 245/615\n",
      "sampling trajectories for possible start locations: 246/615\n",
      "sampling trajectories for possible start locations: 247/615\n",
      "sampling trajectories for possible start locations: 248/615\n",
      "sampling trajectories for possible start locations: 249/615\n",
      "sampling trajectories for possible start locations: 250/615\n",
      "sampling trajectories for possible start locations: 251/615\n",
      "sampling trajectories for possible start locations: 252/615\n",
      "sampling trajectories for possible start locations: 253/615\n",
      "sampling trajectories for possible start locations: 254/615\n",
      "sampling trajectories for possible start locations: 255/615\n",
      "sampling trajectories for possible start locations: 256/615\n",
      "sampling trajectories for possible start locations: 257/615\n",
      "sampling trajectories for possible start locations: 258/615\n",
      "sampling trajectories for possible start locations: 259/615\n",
      "sampling trajectories for possible start locations: 260/615\n",
      "sampling trajectories for possible start locations: 261/615\n",
      "sampling trajectories for possible start locations: 262/615\n",
      "sampling trajectories for possible start locations: 263/615\n",
      "sampling trajectories for possible start locations: 264/615\n",
      "sampling trajectories for possible start locations: 265/615\n",
      "sampling trajectories for possible start locations: 266/615\n",
      "sampling trajectories for possible start locations: 267/615\n",
      "sampling trajectories for possible start locations: 268/615\n",
      "sampling trajectories for possible start locations: 269/615\n",
      "sampling trajectories for possible start locations: 270/615\n",
      "sampling trajectories for possible start locations: 271/615\n",
      "sampling trajectories for possible start locations: 272/615\n",
      "sampling trajectories for possible start locations: 273/615\n",
      "sampling trajectories for possible start locations: 274/615\n",
      "sampling trajectories for possible start locations: 275/615\n",
      "sampling trajectories for possible start locations: 276/615\n",
      "sampling trajectories for possible start locations: 277/615\n",
      "sampling trajectories for possible start locations: 278/615\n",
      "sampling trajectories for possible start locations: 279/615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 280/615\n",
      "sampling trajectories for possible start locations: 281/615\n",
      "sampling trajectories for possible start locations: 282/615\n",
      "sampling trajectories for possible start locations: 283/615\n",
      "sampling trajectories for possible start locations: 284/615\n",
      "sampling trajectories for possible start locations: 285/615\n",
      "sampling trajectories for possible start locations: 286/615\n",
      "sampling trajectories for possible start locations: 287/615\n",
      "sampling trajectories for possible start locations: 288/615\n",
      "sampling trajectories for possible start locations: 289/615\n",
      "sampling trajectories for possible start locations: 290/615\n",
      "sampling trajectories for possible start locations: 291/615\n",
      "sampling trajectories for possible start locations: 292/615\n",
      "sampling trajectories for possible start locations: 293/615\n",
      "sampling trajectories for possible start locations: 294/615\n",
      "sampling trajectories for possible start locations: 295/615\n",
      "sampling trajectories for possible start locations: 296/615\n",
      "sampling trajectories for possible start locations: 297/615\n",
      "sampling trajectories for possible start locations: 298/615\n",
      "sampling trajectories for possible start locations: 299/615\n",
      "sampling trajectories for possible start locations: 300/615\n",
      "sampling trajectories for possible start locations: 301/615\n",
      "sampling trajectories for possible start locations: 302/615\n",
      "sampling trajectories for possible start locations: 303/615\n",
      "sampling trajectories for possible start locations: 304/615\n",
      "sampling trajectories for possible start locations: 305/615\n",
      "sampling trajectories for possible start locations: 306/615\n",
      "sampling trajectories for possible start locations: 307/615\n",
      "sampling trajectories for possible start locations: 308/615\n",
      "sampling trajectories for possible start locations: 309/615\n",
      "sampling trajectories for possible start locations: 310/615\n",
      "sampling trajectories for possible start locations: 311/615\n",
      "sampling trajectories for possible start locations: 312/615\n",
      "sampling trajectories for possible start locations: 313/615\n",
      "sampling trajectories for possible start locations: 314/615\n",
      "sampling trajectories for possible start locations: 315/615\n",
      "sampling trajectories for possible start locations: 316/615\n",
      "sampling trajectories for possible start locations: 317/615\n",
      "sampling trajectories for possible start locations: 318/615\n",
      "sampling trajectories for possible start locations: 319/615\n",
      "sampling trajectories for possible start locations: 320/615\n",
      "sampling trajectories for possible start locations: 321/615\n",
      "sampling trajectories for possible start locations: 322/615\n",
      "sampling trajectories for possible start locations: 323/615\n",
      "sampling trajectories for possible start locations: 324/615\n",
      "sampling trajectories for possible start locations: 325/615\n",
      "sampling trajectories for possible start locations: 326/615\n",
      "sampling trajectories for possible start locations: 327/615\n",
      "sampling trajectories for possible start locations: 328/615\n",
      "sampling trajectories for possible start locations: 329/615\n",
      "sampling trajectories for possible start locations: 330/615\n",
      "sampling trajectories for possible start locations: 331/615\n",
      "sampling trajectories for possible start locations: 332/615\n",
      "sampling trajectories for possible start locations: 333/615\n",
      "sampling trajectories for possible start locations: 334/615\n",
      "sampling trajectories for possible start locations: 335/615\n",
      "sampling trajectories for possible start locations: 336/615\n",
      "sampling trajectories for possible start locations: 337/615\n",
      "sampling trajectories for possible start locations: 338/615\n",
      "sampling trajectories for possible start locations: 339/615\n",
      "sampling trajectories for possible start locations: 340/615\n",
      "sampling trajectories for possible start locations: 341/615\n",
      "sampling trajectories for possible start locations: 342/615\n",
      "sampling trajectories for possible start locations: 343/615\n",
      "sampling trajectories for possible start locations: 344/615\n",
      "sampling trajectories for possible start locations: 345/615\n",
      "sampling trajectories for possible start locations: 346/615\n",
      "sampling trajectories for possible start locations: 347/615\n",
      "sampling trajectories for possible start locations: 348/615\n",
      "sampling trajectories for possible start locations: 349/615\n",
      "sampling trajectories for possible start locations: 350/615\n",
      "sampling trajectories for possible start locations: 351/615\n",
      "sampling trajectories for possible start locations: 352/615\n",
      "sampling trajectories for possible start locations: 353/615\n",
      "sampling trajectories for possible start locations: 354/615\n",
      "sampling trajectories for possible start locations: 355/615\n",
      "sampling trajectories for possible start locations: 356/615\n",
      "sampling trajectories for possible start locations: 357/615\n",
      "sampling trajectories for possible start locations: 358/615\n",
      "sampling trajectories for possible start locations: 359/615\n",
      "sampling trajectories for possible start locations: 360/615\n",
      "sampling trajectories for possible start locations: 361/615\n",
      "sampling trajectories for possible start locations: 362/615\n",
      "sampling trajectories for possible start locations: 363/615\n",
      "sampling trajectories for possible start locations: 364/615\n",
      "sampling trajectories for possible start locations: 365/615\n",
      "sampling trajectories for possible start locations: 366/615\n",
      "sampling trajectories for possible start locations: 367/615\n",
      "sampling trajectories for possible start locations: 368/615\n",
      "sampling trajectories for possible start locations: 369/615\n",
      "sampling trajectories for possible start locations: 370/615\n",
      "sampling trajectories for possible start locations: 371/615\n",
      "sampling trajectories for possible start locations: 372/615\n",
      "sampling trajectories for possible start locations: 373/615\n",
      "sampling trajectories for possible start locations: 374/615\n",
      "sampling trajectories for possible start locations: 375/615\n",
      "sampling trajectories for possible start locations: 376/615\n",
      "sampling trajectories for possible start locations: 377/615\n",
      "sampling trajectories for possible start locations: 378/615\n",
      "sampling trajectories for possible start locations: 379/615\n",
      "sampling trajectories for possible start locations: 380/615\n",
      "sampling trajectories for possible start locations: 381/615\n",
      "sampling trajectories for possible start locations: 382/615\n",
      "sampling trajectories for possible start locations: 383/615\n",
      "sampling trajectories for possible start locations: 384/615\n",
      "sampling trajectories for possible start locations: 385/615\n",
      "sampling trajectories for possible start locations: 386/615\n",
      "sampling trajectories for possible start locations: 387/615\n",
      "sampling trajectories for possible start locations: 388/615\n",
      "sampling trajectories for possible start locations: 389/615\n",
      "sampling trajectories for possible start locations: 390/615\n",
      "sampling trajectories for possible start locations: 391/615\n",
      "sampling trajectories for possible start locations: 392/615\n",
      "sampling trajectories for possible start locations: 393/615\n",
      "sampling trajectories for possible start locations: 394/615\n",
      "sampling trajectories for possible start locations: 395/615\n",
      "sampling trajectories for possible start locations: 396/615\n",
      "sampling trajectories for possible start locations: 397/615\n",
      "sampling trajectories for possible start locations: 398/615\n",
      "sampling trajectories for possible start locations: 399/615\n",
      "sampling trajectories for possible start locations: 400/615\n",
      "sampling trajectories for possible start locations: 401/615\n",
      "sampling trajectories for possible start locations: 402/615\n",
      "sampling trajectories for possible start locations: 403/615\n",
      "sampling trajectories for possible start locations: 404/615\n",
      "sampling trajectories for possible start locations: 405/615\n",
      "sampling trajectories for possible start locations: 406/615\n",
      "sampling trajectories for possible start locations: 407/615\n",
      "sampling trajectories for possible start locations: 408/615\n",
      "sampling trajectories for possible start locations: 409/615\n",
      "sampling trajectories for possible start locations: 410/615\n",
      "sampling trajectories for possible start locations: 411/615\n",
      "sampling trajectories for possible start locations: 412/615\n",
      "sampling trajectories for possible start locations: 413/615\n",
      "sampling trajectories for possible start locations: 414/615\n",
      "sampling trajectories for possible start locations: 415/615\n",
      "sampling trajectories for possible start locations: 416/615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 417/615\n",
      "sampling trajectories for possible start locations: 418/615\n",
      "sampling trajectories for possible start locations: 419/615\n",
      "sampling trajectories for possible start locations: 420/615\n",
      "sampling trajectories for possible start locations: 421/615\n",
      "sampling trajectories for possible start locations: 422/615\n",
      "sampling trajectories for possible start locations: 423/615\n",
      "sampling trajectories for possible start locations: 424/615\n",
      "sampling trajectories for possible start locations: 425/615\n",
      "sampling trajectories for possible start locations: 426/615\n",
      "sampling trajectories for possible start locations: 427/615\n",
      "sampling trajectories for possible start locations: 428/615\n",
      "sampling trajectories for possible start locations: 429/615\n",
      "sampling trajectories for possible start locations: 430/615\n",
      "sampling trajectories for possible start locations: 431/615\n",
      "sampling trajectories for possible start locations: 432/615\n",
      "sampling trajectories for possible start locations: 433/615\n",
      "sampling trajectories for possible start locations: 434/615\n",
      "sampling trajectories for possible start locations: 435/615\n",
      "sampling trajectories for possible start locations: 436/615\n",
      "sampling trajectories for possible start locations: 437/615\n",
      "sampling trajectories for possible start locations: 438/615\n",
      "sampling trajectories for possible start locations: 439/615\n",
      "sampling trajectories for possible start locations: 440/615\n",
      "sampling trajectories for possible start locations: 441/615\n",
      "sampling trajectories for possible start locations: 442/615\n",
      "sampling trajectories for possible start locations: 443/615\n",
      "sampling trajectories for possible start locations: 444/615\n",
      "sampling trajectories for possible start locations: 445/615\n",
      "sampling trajectories for possible start locations: 446/615\n",
      "sampling trajectories for possible start locations: 447/615\n",
      "sampling trajectories for possible start locations: 448/615\n",
      "sampling trajectories for possible start locations: 449/615\n",
      "sampling trajectories for possible start locations: 450/615\n",
      "sampling trajectories for possible start locations: 451/615\n",
      "sampling trajectories for possible start locations: 452/615\n",
      "sampling trajectories for possible start locations: 453/615\n",
      "sampling trajectories for possible start locations: 454/615\n",
      "sampling trajectories for possible start locations: 455/615\n",
      "sampling trajectories for possible start locations: 456/615\n",
      "sampling trajectories for possible start locations: 457/615\n",
      "sampling trajectories for possible start locations: 458/615\n",
      "sampling trajectories for possible start locations: 459/615\n",
      "sampling trajectories for possible start locations: 460/615\n",
      "sampling trajectories for possible start locations: 461/615\n",
      "sampling trajectories for possible start locations: 462/615\n",
      "sampling trajectories for possible start locations: 463/615\n",
      "sampling trajectories for possible start locations: 464/615\n",
      "sampling trajectories for possible start locations: 465/615\n",
      "sampling trajectories for possible start locations: 466/615\n",
      "sampling trajectories for possible start locations: 467/615\n",
      "sampling trajectories for possible start locations: 468/615\n",
      "sampling trajectories for possible start locations: 469/615\n",
      "sampling trajectories for possible start locations: 470/615\n",
      "sampling trajectories for possible start locations: 471/615\n",
      "sampling trajectories for possible start locations: 472/615\n",
      "sampling trajectories for possible start locations: 473/615\n",
      "sampling trajectories for possible start locations: 474/615\n",
      "sampling trajectories for possible start locations: 475/615\n",
      "sampling trajectories for possible start locations: 476/615\n",
      "sampling trajectories for possible start locations: 477/615\n",
      "sampling trajectories for possible start locations: 478/615\n",
      "sampling trajectories for possible start locations: 479/615\n",
      "sampling trajectories for possible start locations: 480/615\n",
      "sampling trajectories for possible start locations: 481/615\n",
      "sampling trajectories for possible start locations: 482/615\n",
      "sampling trajectories for possible start locations: 483/615\n",
      "sampling trajectories for possible start locations: 484/615\n",
      "sampling trajectories for possible start locations: 485/615\n",
      "sampling trajectories for possible start locations: 486/615\n",
      "sampling trajectories for possible start locations: 487/615\n",
      "sampling trajectories for possible start locations: 488/615\n",
      "sampling trajectories for possible start locations: 489/615\n",
      "sampling trajectories for possible start locations: 490/615\n",
      "sampling trajectories for possible start locations: 491/615\n",
      "sampling trajectories for possible start locations: 492/615\n",
      "sampling trajectories for possible start locations: 493/615\n",
      "sampling trajectories for possible start locations: 494/615\n",
      "sampling trajectories for possible start locations: 495/615\n",
      "sampling trajectories for possible start locations: 496/615\n",
      "sampling trajectories for possible start locations: 497/615\n",
      "sampling trajectories for possible start locations: 498/615\n",
      "sampling trajectories for possible start locations: 499/615\n",
      "sampling trajectories for possible start locations: 500/615\n",
      "sampling trajectories for possible start locations: 501/615\n",
      "sampling trajectories for possible start locations: 502/615\n",
      "sampling trajectories for possible start locations: 503/615\n",
      "sampling trajectories for possible start locations: 504/615\n",
      "sampling trajectories for possible start locations: 505/615\n",
      "sampling trajectories for possible start locations: 506/615\n",
      "sampling trajectories for possible start locations: 507/615\n",
      "sampling trajectories for possible start locations: 508/615\n",
      "sampling trajectories for possible start locations: 509/615\n",
      "sampling trajectories for possible start locations: 510/615\n",
      "sampling trajectories for possible start locations: 511/615\n",
      "sampling trajectories for possible start locations: 512/615\n",
      "sampling trajectories for possible start locations: 513/615\n",
      "sampling trajectories for possible start locations: 514/615\n",
      "sampling trajectories for possible start locations: 515/615\n",
      "sampling trajectories for possible start locations: 516/615\n",
      "sampling trajectories for possible start locations: 517/615\n",
      "sampling trajectories for possible start locations: 518/615\n",
      "sampling trajectories for possible start locations: 519/615\n",
      "sampling trajectories for possible start locations: 520/615\n",
      "sampling trajectories for possible start locations: 521/615\n",
      "sampling trajectories for possible start locations: 522/615\n",
      "sampling trajectories for possible start locations: 523/615\n",
      "sampling trajectories for possible start locations: 524/615\n",
      "sampling trajectories for possible start locations: 525/615\n",
      "sampling trajectories for possible start locations: 526/615\n",
      "sampling trajectories for possible start locations: 527/615\n",
      "sampling trajectories for possible start locations: 528/615\n",
      "sampling trajectories for possible start locations: 529/615\n",
      "sampling trajectories for possible start locations: 530/615\n",
      "sampling trajectories for possible start locations: 531/615\n",
      "sampling trajectories for possible start locations: 532/615\n",
      "sampling trajectories for possible start locations: 533/615\n",
      "sampling trajectories for possible start locations: 534/615\n",
      "sampling trajectories for possible start locations: 535/615\n",
      "sampling trajectories for possible start locations: 536/615\n",
      "sampling trajectories for possible start locations: 537/615\n",
      "sampling trajectories for possible start locations: 538/615\n",
      "sampling trajectories for possible start locations: 539/615\n",
      "sampling trajectories for possible start locations: 540/615\n",
      "sampling trajectories for possible start locations: 541/615\n",
      "sampling trajectories for possible start locations: 542/615\n",
      "sampling trajectories for possible start locations: 543/615\n",
      "sampling trajectories for possible start locations: 544/615\n",
      "sampling trajectories for possible start locations: 545/615\n",
      "sampling trajectories for possible start locations: 546/615\n",
      "sampling trajectories for possible start locations: 547/615\n",
      "sampling trajectories for possible start locations: 548/615\n",
      "sampling trajectories for possible start locations: 549/615\n",
      "sampling trajectories for possible start locations: 550/615\n",
      "sampling trajectories for possible start locations: 551/615\n",
      "sampling trajectories for possible start locations: 552/615\n",
      "sampling trajectories for possible start locations: 553/615\n",
      "sampling trajectories for possible start locations: 554/615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories for possible start locations: 555/615\n",
      "sampling trajectories for possible start locations: 556/615\n",
      "sampling trajectories for possible start locations: 557/615\n",
      "sampling trajectories for possible start locations: 558/615\n",
      "sampling trajectories for possible start locations: 559/615\n",
      "sampling trajectories for possible start locations: 560/615\n",
      "sampling trajectories for possible start locations: 561/615\n",
      "sampling trajectories for possible start locations: 562/615\n",
      "sampling trajectories for possible start locations: 563/615\n",
      "sampling trajectories for possible start locations: 564/615\n",
      "sampling trajectories for possible start locations: 565/615\n",
      "sampling trajectories for possible start locations: 566/615\n",
      "sampling trajectories for possible start locations: 567/615\n",
      "sampling trajectories for possible start locations: 568/615\n",
      "sampling trajectories for possible start locations: 569/615\n",
      "sampling trajectories for possible start locations: 570/615\n",
      "sampling trajectories for possible start locations: 571/615\n",
      "sampling trajectories for possible start locations: 572/615\n",
      "sampling trajectories for possible start locations: 573/615\n",
      "sampling trajectories for possible start locations: 574/615\n",
      "sampling trajectories for possible start locations: 575/615\n",
      "sampling trajectories for possible start locations: 576/615\n",
      "sampling trajectories for possible start locations: 577/615\n",
      "sampling trajectories for possible start locations: 578/615\n",
      "sampling trajectories for possible start locations: 579/615\n",
      "sampling trajectories for possible start locations: 580/615\n",
      "sampling trajectories for possible start locations: 581/615\n",
      "sampling trajectories for possible start locations: 582/615\n",
      "sampling trajectories for possible start locations: 583/615\n",
      "sampling trajectories for possible start locations: 584/615\n",
      "sampling trajectories for possible start locations: 585/615\n",
      "sampling trajectories for possible start locations: 586/615\n",
      "sampling trajectories for possible start locations: 587/615\n",
      "sampling trajectories for possible start locations: 588/615\n",
      "sampling trajectories for possible start locations: 589/615\n",
      "sampling trajectories for possible start locations: 590/615\n",
      "sampling trajectories for possible start locations: 591/615\n",
      "sampling trajectories for possible start locations: 592/615\n",
      "sampling trajectories for possible start locations: 593/615\n",
      "sampling trajectories for possible start locations: 594/615\n",
      "sampling trajectories for possible start locations: 595/615\n",
      "sampling trajectories for possible start locations: 596/615\n",
      "sampling trajectories for possible start locations: 597/615\n",
      "sampling trajectories for possible start locations: 598/615\n",
      "sampling trajectories for possible start locations: 599/615\n",
      "sampling trajectories for possible start locations: 600/615\n",
      "sampling trajectories for possible start locations: 601/615\n",
      "sampling trajectories for possible start locations: 602/615\n",
      "sampling trajectories for possible start locations: 603/615\n",
      "sampling trajectories for possible start locations: 604/615\n",
      "sampling trajectories for possible start locations: 605/615\n",
      "sampling trajectories for possible start locations: 606/615\n",
      "sampling trajectories for possible start locations: 607/615\n",
      "sampling trajectories for possible start locations: 608/615\n",
      "sampling trajectories for possible start locations: 609/615\n",
      "sampling trajectories for possible start locations: 610/615\n",
      "sampling trajectories for possible start locations: 611/615\n",
      "sampling trajectories for possible start locations: 612/615\n",
      "sampling trajectories for possible start locations: 613/615\n",
      "sampling trajectories for possible start locations: 614/615\n",
      "sampling trajectories for possible start locations: 615/615\n"
     ]
    }
   ],
   "source": [
    "raw_trajs = sample_trajs(padded_map, map_, w, h, 4, diagonal=True, mode='traverse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajs = map(lambda traj: rescale_trajectory(traj, .2), raw_trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator.human_mcm import Grid_HMM\n",
    "def get_transition_map(trajs, padded_map, w, h, diagonal=False, conditional=True):\n",
    "\n",
    "    mcm = Grid_HMM(np.array(padded_map.shape).astype(int))\n",
    "    for idx, trajectory in enumerate(trajs):\n",
    "        if idx % 100 == 0:\n",
    "            print(\"Add transitions of {}/{} trajectory to the mcm.\".format(idx+1, len(trajs)))\n",
    "        for t in range(trajectory.shape[0] - 2):\n",
    "            \n",
    "            from_ = trajectory[t, :]\n",
    "            current = trajectory[t + 1, :]\n",
    "            to = trajectory[t + 2, :]\n",
    "            mcm.add_transition(from_, current, to)\n",
    "\n",
    "    transition_probs = mcm.get_transition_probs(conditional, diagonal)\n",
    "    return transition_probs[w//2:w+w//2, h//2:h+h//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add transitions of 1/2385 trajectory to the mcm.\n",
      "Add transitions of 101/2385 trajectory to the mcm.\n",
      "Add transitions of 201/2385 trajectory to the mcm.\n",
      "Add transitions of 301/2385 trajectory to the mcm.\n",
      "Add transitions of 401/2385 trajectory to the mcm.\n",
      "Add transitions of 501/2385 trajectory to the mcm.\n",
      "Add transitions of 601/2385 trajectory to the mcm.\n",
      "Add transitions of 701/2385 trajectory to the mcm.\n",
      "Add transitions of 801/2385 trajectory to the mcm.\n",
      "Add transitions of 901/2385 trajectory to the mcm.\n",
      "Add transitions of 1001/2385 trajectory to the mcm.\n",
      "Add transitions of 1101/2385 trajectory to the mcm.\n",
      "Add transitions of 1201/2385 trajectory to the mcm.\n",
      "Add transitions of 1301/2385 trajectory to the mcm.\n",
      "Add transitions of 1401/2385 trajectory to the mcm.\n",
      "Add transitions of 1501/2385 trajectory to the mcm.\n",
      "Add transitions of 1601/2385 trajectory to the mcm.\n",
      "Add transitions of 1701/2385 trajectory to the mcm.\n",
      "Add transitions of 1801/2385 trajectory to the mcm.\n",
      "Add transitions of 1901/2385 trajectory to the mcm.\n",
      "Add transitions of 2001/2385 trajectory to the mcm.\n",
      "Add transitions of 2101/2385 trajectory to the mcm.\n",
      "Add transitions of 2201/2385 trajectory to the mcm.\n",
      "Add transitions of 2301/2385 trajectory to the mcm.\n"
     ]
    }
   ],
   "source": [
    "transition_probs = get_transition_map(raw_trajs, padded_map, w, h, diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 3, 3, 3)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (2, 1), (1, 0), (0, 1), (2, 2), (2, 0), (0, 2), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "diagonal=True\n",
    "if diagonal:\n",
    "    velocities = [[0, 1], [1, 0], [0, -1], [-1, 0],\n",
    "                  [1, 1], [1, -1], [-1, 1], [-1, -1]]\n",
    "else:\n",
    "    velocities = [[0, 1], [1, 0], [0, -1], [-1, 0]]\n",
    "\n",
    "idxs = map(lambda vel: Grid_HMM.two_d_vel_to_idx(vel), velocities)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill in 0 entries to keep motion\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# keep motion for empty entries\n",
    "for idx_xy in np.ndindex(map_.shape):\n",
    "    for idx_vel_last in idxs:\n",
    "        if np.all(transition_probs[idx_xy+idx_vel_last]==0):\n",
    "            transition_probs[idx_xy+idx_vel_last+idx_vel_last] = 1\n",
    "            count += 1\n",
    "print(\"fill in %d entries to keep motion\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 24, 0, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = np.random.randint(32), np.random.randint(32)\n",
    "vel_x, vel_y = np.random.randint(3), np.random.randint(3)\n",
    "print(x, y, vel_x, vel_y)\n",
    "transition_probs[x, y, vel_x, vel_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isclose(a, b, rel_tol=1e-09, abs_tol=0.0):\n",
    "    return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.ndindex(map_.shape):\n",
    "    if not isclose(transition_probs[idx].sum(), 8):\n",
    "        print(idx)\n",
    "        print(transition_probs[idx].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "map_axes = fig.add_subplot(111)\n",
    "plot = Plot(map_axes, map_, .2, title='')\n",
    "from utils.occ_map_utils import greens_cm\n",
    "plot.add_custom_image(\"gaussian_axes\", image=np.zeros((300, 300)), cmap=greens_cm, extent=(0, 6.4, 0. ,6.4), zorder=-1)\n",
    "plot.axes.set_xlabel('m')\n",
    "plot.axes.set_ylabel('m')\n",
    "fig_1 = plt.figure(figsize=(5, 5))\n",
    "fig.canvas.mpl_connect('button_press_event', lambda event: onclick_traj_random(event, fig, plot, fig_1, raw_trajs, transition_probs, w=w, h=h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/ful7rng/Desktop/thesis/writting_materials/91_T_section_probs_cost_1_2_cost_2_1.npy\", transition_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blur spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blurred_probs = transition_probs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = []\n",
    "for idx_xy in np.ndindex(map_.shape):\n",
    "    for idx_vel_last in idxs:\n",
    "        max_idx = np.argmax(transition_probs[idx_xy+idx_vel_last])\n",
    "        max_idx = np.unravel_index(max_idx, (3, 3))\n",
    "        if not max_idx == idx_vel_last:\n",
    "            turns.append(idx_xy+idx_vel_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 0, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fe405579f90>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "ax = plt.imshow(transition_probs[turns[0]])\n",
    "print(turns[0])\n",
    "plt.colorbar(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fe404c6aa10>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import nd_gaussian\n",
    "blur_extent = 9\n",
    "var = 1.2\n",
    "half_be = blur_extent // 2\n",
    "gaussian = nd_gaussian((blur_extent, blur_extent), (half_be, half_be), var)\n",
    "gaussian /= gaussian.max()\n",
    "plt.figure()\n",
    "ax = plt.imshow(gaussian)\n",
    "plt.colorbar(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_probs = transition_probs.copy()\n",
    "blurred_probs = np.pad(blurred_probs, ((half_be, half_be), (half_be, half_be),\n",
    "                           (0, 0), (0, 0), (0, 0), (0, 0)),\n",
    "                            mode='constant', constant_values=0)\n",
    "\n",
    "for turn in turns:\n",
    "    temp = gaussian[..., None, None] * transition_probs[turn]\n",
    "    x, y = turn[0], turn[1]\n",
    "    vel_x, vel_y = turn[2], turn[3]\n",
    "    blurred_probs[x:x+blur_extent, y:y+blur_extent, vel_x, vel_y] += temp\n",
    "blurred_probs = blurred_probs[half_be:half_be + w, half_be:half_be + h]\n",
    "\n",
    "# normalize\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    blurred_probs /= blurred_probs.sum(axis=(4, 5), keepdims=True)\n",
    "    blurred_probs[~np.isfinite(blurred_probs)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in np.ndindex(map_.shape):\n",
    "    if not isclose(blurred_probs[idx].sum(), 8):\n",
    "        print(idx)\n",
    "        print(blurred_probs[idx].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 3, 3, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   4.74501979e-10],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurred_probs[23, 21, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/ful7rng/Desktop/thesis/writting_materials/91_T_section_probs_blurred_var_1.2_extent_9_cost_1_2_cost_2_1.npy\", blurred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_trajs_example = {}\n",
    "map_trajs_example['map'] = map_\n",
    "map_trajs_example['trajectories'] = raw_trajs\n",
    "map_trajs_example['probs'] = transition_probs\n",
    "map_trajs_example['blurred_probs_var_1.2_extent_9'] = blurred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import pickle_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save(\"/home/ful7rng/Desktop/thesis/writting_materials/map_traj_example.pkl\", map_trajs_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_4d_tensor\n",
    "\n",
    "def onclick(event, models, anim, fig_1, fig_2, fig_3, ma_plot, vel_plot, merge_vel_plot, final_vel_plot):\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    coords = np.floor(np.array([ix, iy]) / models[0].map_res).astype(int)\n",
    "    print(coords)\n",
    "    \n",
    "    all_axes = [plot.axes for plot in anim.plots]\n",
    "    \n",
    "    for i, ax in enumerate(all_axes):\n",
    "\n",
    "        # For infomation, print which axes the click was in\n",
    "        if ax == event.inaxes:\n",
    "            print \"Click is in axes ax{}\".format(i+1)\n",
    "            break\n",
    "            \n",
    "    clicked = np.zeros_like(models[0].map)\n",
    "    x, y = coords[0], coords[1]\n",
    "    clicked[x, y] = 1\n",
    "    for plot in anim.plots:\n",
    "        plot.set_axes_data(\"occupancy_axes\", clicked)\n",
    "    anim.fig.canvas.draw()\n",
    "    \n",
    "    fig_1.clear()\n",
    "    fig_2.clear()\n",
    "    \n",
    "    \n",
    "    if models[i].kernels.ndim == 6:\n",
    "        kernel = models[i].kernels[x, y]\n",
    "        condi_prob = models[i].nn_probs[x, y]\n",
    "    else:\n",
    "        kernel = models[i].kernels\n",
    "        condi_prob = models[i].kernels\n",
    "        \n",
    "#     print(kernel.shape)\n",
    "#     print(condi_prob.shape)\n",
    "    print(np.sum(kernel, axis=(2, 3)))\n",
    "    plot_4d_tensor(condi_prob, fig=fig_1)\n",
    "    plot_4d_tensor(kernel, fig=fig_2)\n",
    "    if hasattr(models[i], 'apply_vel_mask') and models[i].apply_vel_mask:\n",
    "        print(\"plot vel mask\")\n",
    "        ma_plot.set_axes_data(\"occupancy_axes\", models[i].vel_mask[x, y])\n",
    "    else:\n",
    "        ma_plot.set_axes_data(\"occupancy_axes\", models[i].ma_vel)\n",
    "    vel_plot.set_axes_data(\"occupancy_axes\", models[i].P_Vt_pred[x, y])\n",
    "    merge_vel_plot.set_axes_data(\"occupancy_axes\", models[i].P_Vt_merged[x, y])\n",
    "    final_vel_plot.set_axes_data(\"occupancy_axes\", models[i].P_Vt[x, y])\n",
    "    #print(models[i].P_Vt[x, y])\n",
    "    fig_1.canvas.draw()\n",
    "    fig_2.canvas.draw()\n",
    "    fig_3.canvas.draw()\n",
    "    \n",
    "    model_names = map(lambda model: model.name, models)\n",
    "    occs = map(lambda model: model.P_Ot[x, y], models)\n",
    "    for name, occ in zip(model_names, occs):\n",
    "        print(\"loc ({}, {}) of model {} has occupancy of {}\".format(x, y, name, occ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_press(event, animation):\n",
    "    global scenes\n",
    "    if event.key == 'n':\n",
    "        idx = np.random.choice(np.arange(len(scenes)))\n",
    "        print(idx)\n",
    "        scene = scenes[idx]\n",
    "        animation.update(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diagonal = True\n",
    "if diagonal:\n",
    "    model_name = '23_ALL_MAPS_EIGHT_DIRECTIONS'\n",
    "    model_name = '04_DIAGONAL_TRUE_CONDITIONAL_TRUE'\n",
    "else:\n",
    "    # model_name = '20_ALL_MAPS_W_MASK'\n",
    "    model_name = '04_DIAGONAL_FALSE_CONDITIONAL_FALSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_predict = True\n",
    "simulated_data = False\n",
    "kwargs = dict(omega=0.01,\n",
    "                  extent=7,\n",
    "                  noise_var=0.3,\n",
    "                  measurement_lost=8,\n",
    "                  verbose=False)\n",
    "\n",
    "naive_bofum = naiveBOFUM(map_, name='BOFUM', simulated_data=simulated_data, **kwargs)\n",
    "bofum = conditionalBOFUM(map_, model_name,\n",
    "                               name = 'BOFUM acc. with new trans_porbs',\n",
    "                               simulated_data=simulated_data,\n",
    "                               force_predict=force_predict,\n",
    "                               acceleration_interpretation=True,\n",
    "                               nn_probs = transition_probs,\n",
    "                               **kwargs)\n",
    "\n",
    "# bofum_old = conditionalBOFUM(map_, model_name,\n",
    "#                                name = 'BOFUM with n. o. as acceleration',\n",
    "#                                simulated_data=simulated_data,\n",
    "#                                force_predict=force_predict,\n",
    "#                                acceleration_interpretation=True,\n",
    "#                                **kwargs)\n",
    "\n",
    "# bofum_blur = conditionalBOFUM(map_, model_name,\n",
    "#                                name = 'BOFUM acc new with blur_spatially',\n",
    "#                                simulated_data=simulated_data,\n",
    "#                                force_predict=force_predict,\n",
    "#                                acceleration_interpretation=True,\n",
    "#                                nn_probs = blurred_probs,\n",
    "#                                **kwargs)\n",
    "\n",
    "# bofum_blur_ma = conditionalBOFUM(map_, model_name,\n",
    "#                                name = 'BOFUM acc new with blur and ma',\n",
    "#                                simulated_data=simulated_data,\n",
    "#                                force_predict=force_predict,\n",
    "#                                acceleration_interpretation=True,\n",
    "#                                keep_motion=True,\n",
    "#                                nn_probs = blurred_probs,\n",
    "#                                **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(naive_bofum)\n",
    "models.append(bofum)\n",
    "# models.append(bofum_blur)\n",
    "# models.append(bofum_blur_ma)\n",
    "# models.append(bofum_old)\n",
    "\n",
    "# models.append(bofum_ma)\n",
    "# models.append(bofum_vm)\n",
    "# models.append(bofum_keep)\n",
    "# models.append(bofum_vm_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_copy = deepcopy(scene)\n",
    "processed_scene_copy = BOFUMRealdata.scene_preprocessing(scene_copy)\n",
    "#animate_scenes([processed_scene_copy])\n",
    "laser_frequency = 12\n",
    "tracking_to = processed_scene_copy.hits.shape[0]\n",
    "num_steps = tracking_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_generator = naiveBOFUM(map_, name='BOFUM', simulated_data=True, noise_var=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling trajectories: 1/1\n",
      "time out\n",
      "sampling trajectories: 1/1\n",
      "time out\n",
      "sampling trajectories: 1/1\n",
      "time out\n",
      "sampling trajectories: 1/1\n"
     ]
    }
   ],
   "source": [
    "num_steps = 48\n",
    "scene_generator.initialize(np.random.randint(1, 4), num_steps, diagonal=True)\n",
    "scene = scene_generator.trajs_to_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame = 0\n",
      "frame = 1\n",
      "frame = 2\n",
      "frame = 3\n",
      "frame = 4\n",
      "frame = 5\n",
      "frame = 6\n",
      "frame = 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 57]\n",
      "Click is in axes ax2\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (40, 57) of model BOFUM has occupancy of 3.02788097625e-17\n",
      "loc (40, 57) of model BOFUM acc. with new trans_porbs has occupancy of 3.36431219583e-17\n",
      "[42 67]\n",
      "Click is in axes ax2\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (42, 67) of model BOFUM has occupancy of 3.25216845597e-17\n",
      "loc (42, 67) of model BOFUM acc. with new trans_porbs has occupancy of 5.27075577347e-17\n",
      "frame = 8\n",
      "frame = 9\n",
      "frame = 10\n",
      "frame = 11\n",
      "frame = 12\n",
      "frame = 13\n",
      "frame = 14\n",
      "frame = 15\n",
      "frame = 16\n",
      "frame = 17\n",
      "frame = 18\n",
      "frame = 19\n",
      "frame = 20\n",
      "frame = 21\n",
      "frame = 22\n",
      "frame = 23\n",
      "frame = 24\n",
      "frame = 25\n",
      "frame = 26\n",
      "frame = 27\n",
      "frame = 28\n",
      "frame = 29\n",
      "frame = 30\n",
      "frame = 31\n",
      "frame = 32\n",
      "frame = 33\n",
      "frame = 34\n",
      "frame = 35\n",
      "frame = 36\n",
      "frame = 37\n",
      "frame = 38\n",
      "frame = 39\n",
      "frame = 40\n",
      "frame = 41\n",
      "frame = 42\n",
      "frame = 43\n",
      "frame = 44\n",
      "frame = 45\n",
      "frame = 46\n",
      "frame = 47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ani = TrackingAnimRealdata(models, num_steps, scene,\n",
    "                                plot_map=True,\n",
    "                                plot_seen=True)\n",
    "\n",
    "fig_1 = plt.figure(figsize=(6, 5))\n",
    "fig_2 = plt.figure(figsize=(6, 5))\n",
    "fig_size = (5 * 4, 5)\n",
    "fig_3 = plt.figure(figsize=fig_size)\n",
    "ma_ax = fig_3.add_subplot(141)\n",
    "ma_plot = Plot(ma_ax, bofum.ma_vel, 1, False, False, False, colorbar_on='occupancy_axes', title='moving average vel/ vel mask')\n",
    "vel_ax = fig_3.add_subplot(142)\n",
    "vel_plot = Plot(vel_ax, bofum.ma_vel, 1, False, False, False, colorbar_on='occupancy_axes', title='predicted vel')\n",
    "merge_vel_ax = fig_3.add_subplot(143)\n",
    "merge_vel_plot = Plot(merge_vel_ax, bofum.ma_vel, 1, False, False, False, colorbar_on='occupancy_axes', title='merged velocity')\n",
    "final_vel_ax = fig_3.add_subplot(144)\n",
    "final_vel_plot = Plot(final_vel_ax, bofum.ma_vel, 1, False, False, False, colorbar_on='occupancy_axes', title='velocity')\n",
    "\n",
    "ani.fig.canvas.mpl_connect('button_press_event', lambda event: onclick(event, models, ani, fig_1, fig_2, fig_3, ma_plot, vel_plot, merge_vel_plot, final_vel_plot))\n",
    "ani.fig.canvas.mpl_connect('key_press_event', lambda event: on_press(event, ani))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame = 7\n",
      "motion factor :0.5\n",
      "frame = 8\n",
      "motion factor :0.3\n",
      "frame = 9\n",
      "motion factor :0.18\n",
      "frame = 10\n",
      "motion factor :0.108\n",
      "frame = 11\n",
      "motion factor :0.0648\n",
      "frame = 12\n",
      "motion factor :0.03888\n",
      "frame = 13\n",
      "motion factor :0.023328\n",
      "frame = 14\n",
      "motion factor :0.0139968\n",
      "frame = 15\n",
      "motion factor :0.00839808\n",
      "frame = 16\n",
      "motion factor :0.005038848\n",
      "frame = 17\n",
      "motion factor :0.0030233088\n",
      "frame = 18\n",
      "motion factor :0.00181398528\n",
      "frame = 19\n",
      "motion factor :0.001088391168\n",
      "frame = 20\n",
      "motion factor :0.0006530347008\n",
      "frame = 0\n",
      "frame = 1\n",
      "frame = 2\n",
      "frame = 3\n",
      "frame = 4\n",
      "frame = 5\n",
      "frame = 6\n",
      "frame = 7\n",
      "motion factor :0.5\n",
      "frame = 8\n",
      "motion factor :0.3\n",
      "frame = 9\n",
      "motion factor :0.18\n",
      "frame = 10\n",
      "motion factor :0.108\n",
      "frame = 11\n",
      "motion factor :0.0648\n",
      "frame = 12\n",
      "motion factor :0.03888\n",
      "[18 17]\n",
      "Click is in axes ax4\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (18, 17) of model BOFUM has occupancy of 0.000230148495218\n",
      "loc (18, 17) of model BOFUM acc. with new trans_porbs has occupancy of 0.0013776551307\n",
      "loc (18, 17) of model BOFUM acc new with blur_spatially has occupancy of 0.00895214856641\n",
      "loc (18, 17) of model BOFUM acc new with blur and ma has occupancy of 0.0571331138913\n",
      "loc (18, 17) of model BOFUM with n. o. as acceleration has occupancy of 0.0363631164171\n",
      "[22 24]\n",
      "Click is in axes ax2\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (22, 24) of model BOFUM has occupancy of 0.00419020978501\n",
      "loc (22, 24) of model BOFUM acc. with new trans_porbs has occupancy of 2.53761109741e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur_spatially has occupancy of 7.86158129039e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur and ma has occupancy of 0.00111939473448\n",
      "loc (22, 24) of model BOFUM with n. o. as acceleration has occupancy of 9.96419990629e-07\n",
      "[22 24]\n",
      "Click is in axes ax2\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (22, 24) of model BOFUM has occupancy of 0.00419020978501\n",
      "loc (22, 24) of model BOFUM acc. with new trans_porbs has occupancy of 2.53761109741e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur_spatially has occupancy of 7.86158129039e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur and ma has occupancy of 0.00111939473448\n",
      "loc (22, 24) of model BOFUM with n. o. as acceleration has occupancy of 9.96419990629e-07\n",
      "[22 24]\n",
      "Click is in axes ax3\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (22, 24) of model BOFUM has occupancy of 0.00419020978501\n",
      "loc (22, 24) of model BOFUM acc. with new trans_porbs has occupancy of 2.53761109741e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur_spatially has occupancy of 7.86158129039e-05\n",
      "loc (22, 24) of model BOFUM acc new with blur and ma has occupancy of 0.00111939473448\n",
      "loc (22, 24) of model BOFUM with n. o. as acceleration has occupancy of 9.96419990629e-07\n",
      "[22 23]\n",
      "Click is in axes ax3\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (22, 23) of model BOFUM has occupancy of 0.00496162973353\n",
      "loc (22, 23) of model BOFUM acc. with new trans_porbs has occupancy of 1.97871327103e-05\n",
      "loc (22, 23) of model BOFUM acc new with blur_spatially has occupancy of 8.79494190462e-05\n",
      "loc (22, 23) of model BOFUM acc new with blur and ma has occupancy of 0.00198461068383\n",
      "loc (22, 23) of model BOFUM with n. o. as acceleration has occupancy of 1.49073901357e-06\n",
      "[23 24]\n",
      "Click is in axes ax3\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (23, 24) of model BOFUM has occupancy of 5.69889405232e-05\n",
      "loc (23, 24) of model BOFUM acc. with new trans_porbs has occupancy of 6.70332229269e-06\n",
      "loc (23, 24) of model BOFUM acc new with blur_spatially has occupancy of 5.11362215035e-05\n",
      "loc (23, 24) of model BOFUM acc new with blur and ma has occupancy of 0.000586093309604\n",
      "loc (23, 24) of model BOFUM with n. o. as acceleration has occupancy of 3.63537803527e-07\n",
      "[23 23]\n",
      "Click is in axes ax3\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (23, 23) of model BOFUM has occupancy of 6.23583950505e-05\n",
      "loc (23, 23) of model BOFUM acc. with new trans_porbs has occupancy of 7.26774078252e-07\n",
      "loc (23, 23) of model BOFUM acc new with blur_spatially has occupancy of 3.97377703787e-05\n",
      "loc (23, 23) of model BOFUM acc new with blur and ma has occupancy of 0.000627020638467\n",
      "loc (23, 23) of model BOFUM with n. o. as acceleration has occupancy of 5.11137118631e-07\n",
      "[23 23]\n",
      "Click is in axes ax2\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (23, 23) of model BOFUM has occupancy of 6.23583950505e-05\n",
      "loc (23, 23) of model BOFUM acc. with new trans_porbs has occupancy of 7.26774078252e-07\n",
      "loc (23, 23) of model BOFUM acc new with blur_spatially has occupancy of 3.97377703787e-05\n",
      "loc (23, 23) of model BOFUM acc new with blur and ma has occupancy of 0.000627020638467\n",
      "loc (23, 23) of model BOFUM with n. o. as acceleration has occupancy of 5.11137118631e-07\n",
      "[22 23]\n",
      "Click is in axes ax3\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.]]\n",
      "loc (22, 23) of model BOFUM has occupancy of 0.00496162973353\n",
      "loc (22, 23) of model BOFUM acc. with new trans_porbs has occupancy of 1.97871327103e-05\n",
      "loc (22, 23) of model BOFUM acc new with blur_spatially has occupancy of 8.79494190462e-05\n",
      "loc (22, 23) of model BOFUM acc new with blur and ma has occupancy of 0.00198461068383\n",
      "loc (22, 23) of model BOFUM with n. o. as acceleration has occupancy of 1.49073901357e-06\n"
     ]
    }
   ],
   "source": [
    "np.sum(blurred_probs[28, 20], axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
